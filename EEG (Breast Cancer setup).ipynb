{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import validation_curve\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7','F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19',\n",
    "          'F20','F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28','29', 'F30', 'F31', 'F32','F33', 'F34', 'F35',\n",
    "          'F36','F37', 'F38', 'F39', 'F40', 'F41', 'F42', 'F43', 'F44','45', 'F46', 'F47', 'F48','F49', 'F50', 'F51', 'F52', \n",
    "          'F53', 'F54', 'F55','F56', 'F57', 'F58', 'F59', 'F60','F61', 'F62', 'F63', 'F64', 'F65', 'F66', 'F67','F68', \n",
    "          'F69', 'F70','F71', 'F72','Valence','Arousal']\n",
    "\n",
    "# happy_df = pd.read_csv(dirname + datasethappy, header=0, names=names1)\n",
    "df = pd.read_csv('C:/Users/DELL/S01/finals/Final_mfcc_Train_S01.csv',  header =None, index_col=None,names=names1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=1, how='any', thresh=None, subset=None, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F65</th>\n",
       "      <th>F66</th>\n",
       "      <th>F67</th>\n",
       "      <th>F68</th>\n",
       "      <th>F69</th>\n",
       "      <th>F70</th>\n",
       "      <th>F71</th>\n",
       "      <th>F72</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.00</td>\n",
       "      <td>66.10</td>\n",
       "      <td>-20.6</td>\n",
       "      <td>-36.5</td>\n",
       "      <td>-8.25</td>\n",
       "      <td>-13.6</td>\n",
       "      <td>7.57</td>\n",
       "      <td>-10.50</td>\n",
       "      <td>-45.2</td>\n",
       "      <td>-53.00</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.90</td>\n",
       "      <td>-26.20</td>\n",
       "      <td>25.4000</td>\n",
       "      <td>4.89</td>\n",
       "      <td>-45.50</td>\n",
       "      <td>-71.5</td>\n",
       "      <td>-70.3</td>\n",
       "      <td>-77.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52.30</td>\n",
       "      <td>85.20</td>\n",
       "      <td>10.4</td>\n",
       "      <td>19.5</td>\n",
       "      <td>-25.40</td>\n",
       "      <td>-27.7</td>\n",
       "      <td>-8.10</td>\n",
       "      <td>4.32</td>\n",
       "      <td>15.2</td>\n",
       "      <td>8.46</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.50</td>\n",
       "      <td>-16.40</td>\n",
       "      <td>22.5000</td>\n",
       "      <td>36.30</td>\n",
       "      <td>-18.10</td>\n",
       "      <td>-71.0</td>\n",
       "      <td>-55.2</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.62</td>\n",
       "      <td>15.00</td>\n",
       "      <td>-16.8</td>\n",
       "      <td>-20.8</td>\n",
       "      <td>135.00</td>\n",
       "      <td>65.2</td>\n",
       "      <td>-16.80</td>\n",
       "      <td>-2.30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.02</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>9.78</td>\n",
       "      <td>-28.9000</td>\n",
       "      <td>-18.30</td>\n",
       "      <td>23.70</td>\n",
       "      <td>58.1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>37.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.88</td>\n",
       "      <td>-8.53</td>\n",
       "      <td>-26.5</td>\n",
       "      <td>-39.0</td>\n",
       "      <td>-34.90</td>\n",
       "      <td>-44.8</td>\n",
       "      <td>-40.70</td>\n",
       "      <td>-38.90</td>\n",
       "      <td>20.8</td>\n",
       "      <td>64.70</td>\n",
       "      <td>...</td>\n",
       "      <td>3.66</td>\n",
       "      <td>17.60</td>\n",
       "      <td>-0.0467</td>\n",
       "      <td>-3.93</td>\n",
       "      <td>-1.07</td>\n",
       "      <td>15.8</td>\n",
       "      <td>33.1</td>\n",
       "      <td>34.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.23</td>\n",
       "      <td>9.13</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>-18.7</td>\n",
       "      <td>-30.10</td>\n",
       "      <td>-33.2</td>\n",
       "      <td>2.85</td>\n",
       "      <td>20.30</td>\n",
       "      <td>10.9</td>\n",
       "      <td>-13.70</td>\n",
       "      <td>...</td>\n",
       "      <td>7.49</td>\n",
       "      <td>17.20</td>\n",
       "      <td>-15.9000</td>\n",
       "      <td>-5.11</td>\n",
       "      <td>25.70</td>\n",
       "      <td>53.2</td>\n",
       "      <td>64.2</td>\n",
       "      <td>69.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      F1     F2    F3    F4      F5    F6     F7     F8    F9    F10  ...  \\\n",
       "0  45.00  66.10 -20.6 -36.5   -8.25 -13.6   7.57 -10.50 -45.2 -53.00  ...   \n",
       "1  52.30  85.20  10.4  19.5  -25.40 -27.7  -8.10   4.32  15.2   8.46  ...   \n",
       "2   7.62  15.00 -16.8 -20.8  135.00  65.2 -16.80  -2.30  10.0   6.02  ...   \n",
       "3  -5.88  -8.53 -26.5 -39.0  -34.90 -44.8 -40.70 -38.90  20.8  64.70  ...   \n",
       "4   3.23   9.13 -13.2 -18.7  -30.10 -33.2   2.85  20.30  10.9 -13.70  ...   \n",
       "\n",
       "     F65    F66      F67    F68    F69   F70   F71    F72  Valence  Arousal  \n",
       "0 -15.90 -26.20  25.4000   4.89 -45.50 -71.5 -70.3 -77.30      1.0      1.0  \n",
       "1 -11.50 -16.40  22.5000  36.30 -18.10 -71.0 -55.2   2.19      1.0      1.0  \n",
       "2  -1.33   9.78 -28.9000 -18.30  23.70  58.1  59.8  37.00      1.0      1.0  \n",
       "3   3.66  17.60  -0.0467  -3.93  -1.07  15.8  33.1  34.30      1.0      1.0  \n",
       "4   7.49  17.20 -15.9000  -5.11  25.70  53.2  64.2  69.40      1.0      1.0  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F65</th>\n",
       "      <th>F66</th>\n",
       "      <th>F67</th>\n",
       "      <th>F68</th>\n",
       "      <th>F69</th>\n",
       "      <th>F70</th>\n",
       "      <th>F71</th>\n",
       "      <th>F72</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>472.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.000517</td>\n",
       "      <td>-0.002297</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>-0.001148</td>\n",
       "      <td>-0.001593</td>\n",
       "      <td>-0.000297</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20.749973</td>\n",
       "      <td>35.703958</td>\n",
       "      <td>31.017005</td>\n",
       "      <td>41.656940</td>\n",
       "      <td>30.809207</td>\n",
       "      <td>34.024614</td>\n",
       "      <td>30.864090</td>\n",
       "      <td>28.061227</td>\n",
       "      <td>32.300316</td>\n",
       "      <td>48.621158</td>\n",
       "      <td>...</td>\n",
       "      <td>21.904235</td>\n",
       "      <td>32.681913</td>\n",
       "      <td>26.656454</td>\n",
       "      <td>23.509190</td>\n",
       "      <td>30.237163</td>\n",
       "      <td>50.913991</td>\n",
       "      <td>47.589578</td>\n",
       "      <td>49.876249</td>\n",
       "      <td>1.001061</td>\n",
       "      <td>1.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-35.400000</td>\n",
       "      <td>-71.900000</td>\n",
       "      <td>-61.800000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-56.800000</td>\n",
       "      <td>-81.500000</td>\n",
       "      <td>-79.500000</td>\n",
       "      <td>-83.700000</td>\n",
       "      <td>-110.000000</td>\n",
       "      <td>-183.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-37.200000</td>\n",
       "      <td>-72.000000</td>\n",
       "      <td>-62.400000</td>\n",
       "      <td>-54.600000</td>\n",
       "      <td>-120.000000</td>\n",
       "      <td>-200.000000</td>\n",
       "      <td>-178.000000</td>\n",
       "      <td>-144.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-14.900000</td>\n",
       "      <td>-27.625000</td>\n",
       "      <td>-20.425000</td>\n",
       "      <td>-27.225000</td>\n",
       "      <td>-22.325000</td>\n",
       "      <td>-26.725000</td>\n",
       "      <td>-22.100000</td>\n",
       "      <td>-17.950000</td>\n",
       "      <td>-21.875000</td>\n",
       "      <td>-33.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.900000</td>\n",
       "      <td>-22.700000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>-16.025000</td>\n",
       "      <td>-21.300000</td>\n",
       "      <td>-30.875000</td>\n",
       "      <td>-32.350000</td>\n",
       "      <td>-31.875000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.215000</td>\n",
       "      <td>-5.120000</td>\n",
       "      <td>-4.550000</td>\n",
       "      <td>-0.838000</td>\n",
       "      <td>-4.205000</td>\n",
       "      <td>-1.038500</td>\n",
       "      <td>-3.460000</td>\n",
       "      <td>-2.375000</td>\n",
       "      <td>0.882500</td>\n",
       "      <td>3.020000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.900000</td>\n",
       "      <td>-2.110000</td>\n",
       "      <td>-2.200000</td>\n",
       "      <td>1.735000</td>\n",
       "      <td>1.435000</td>\n",
       "      <td>3.130000</td>\n",
       "      <td>1.430000</td>\n",
       "      <td>2.085000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.225000</td>\n",
       "      <td>23.425000</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>25.900000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>22.425000</td>\n",
       "      <td>18.625000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>20.725000</td>\n",
       "      <td>33.275000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.157500</td>\n",
       "      <td>20.900000</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>14.825000</td>\n",
       "      <td>21.025000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>30.525000</td>\n",
       "      <td>33.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>151.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>99.100000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>90.800000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>84.400000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               F1          F2          F3          F4          F5          F6  \\\n",
       "count  472.000000  472.000000  472.000000  472.000000  472.000000  472.000000   \n",
       "mean     0.000686    0.000871    0.001799    0.000926   -0.000576   -0.000517   \n",
       "std     20.749973   35.703958   31.017005   41.656940   30.809207   34.024614   \n",
       "min    -35.400000  -71.900000  -61.800000 -100.000000  -56.800000  -81.500000   \n",
       "25%    -14.900000  -27.625000  -20.425000  -27.225000  -22.325000  -26.725000   \n",
       "50%     -4.215000   -5.120000   -4.550000   -0.838000   -4.205000   -1.038500   \n",
       "75%     10.225000   23.425000   13.025000   25.900000   17.200000   22.425000   \n",
       "max    151.000000  122.000000  120.000000  133.000000  135.000000  136.000000   \n",
       "\n",
       "               F7          F8          F9         F10  ...         F65  \\\n",
       "count  472.000000  472.000000  472.000000  472.000000  ...  472.000000   \n",
       "mean    -0.002297    0.000498   -0.000290   -0.001977  ...    0.000489   \n",
       "std     30.864090   28.061227   32.300316   48.621158  ...   21.904235   \n",
       "min    -79.500000  -83.700000 -110.000000 -183.000000  ...  -37.200000   \n",
       "25%    -22.100000  -17.950000  -21.875000  -33.400000  ...  -14.900000   \n",
       "50%     -3.460000   -2.375000    0.882500    3.020000  ...   -3.900000   \n",
       "75%     18.625000   19.100000   20.725000   33.275000  ...    9.157500   \n",
       "max    123.000000   99.100000  108.000000  133.000000  ...  104.000000   \n",
       "\n",
       "              F66         F67         F68         F69         F70         F71  \\\n",
       "count  472.000000  472.000000  472.000000  472.000000  472.000000  472.000000   \n",
       "mean    -0.001997    0.000522    0.000257   -0.001148   -0.001593   -0.000297   \n",
       "std     32.681913   26.656454   23.509190   30.237163   50.913991   47.589578   \n",
       "min    -72.000000  -62.400000  -54.600000 -120.000000 -200.000000 -178.000000   \n",
       "25%    -22.700000  -18.000000  -16.025000  -21.300000  -30.875000  -32.350000   \n",
       "50%     -2.110000   -2.200000    1.735000    1.435000    3.130000    1.430000   \n",
       "75%     20.900000   14.100000   14.825000   21.025000   33.000000   30.525000   \n",
       "max     90.800000  110.000000   84.400000  105.000000  130.000000  149.000000   \n",
       "\n",
       "              F72     Valence     Arousal  \n",
       "count  472.000000  472.000000  472.000000  \n",
       "mean    -0.001199    0.000000    0.000000  \n",
       "std     49.876249    1.001061    1.001061  \n",
       "min   -144.000000   -1.000000   -1.000000  \n",
       "25%    -31.875000   -1.000000   -1.000000  \n",
       "50%      2.085000    0.000000    0.000000  \n",
       "75%     33.700000    1.000000    1.000000  \n",
       "max    157.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 74 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         count      mean        std    min     25%    50%     75%    max\n",
      "F1       472.0  0.000686  20.749973  -35.4 -14.900 -4.215  10.225  151.0\n",
      "F2       472.0  0.000871  35.703958  -71.9 -27.625 -5.120  23.425  122.0\n",
      "F3       472.0  0.001799  31.017005  -61.8 -20.425 -4.550  13.025  120.0\n",
      "F4       472.0  0.000926  41.656940 -100.0 -27.225 -0.838  25.900  133.0\n",
      "F5       472.0 -0.000576  30.809207  -56.8 -22.325 -4.205  17.200  135.0\n",
      "...        ...       ...        ...    ...     ...    ...     ...    ...\n",
      "F70      472.0 -0.001593  50.913991 -200.0 -30.875  3.130  33.000  130.0\n",
      "F71      472.0 -0.000297  47.589578 -178.0 -32.350  1.430  30.525  149.0\n",
      "F72      472.0 -0.001199  49.876249 -144.0 -31.875  2.085  33.700  157.0\n",
      "Valence  472.0  0.000000   1.001061   -1.0  -1.000  0.000   1.000    1.0\n",
      "Arousal  472.0  0.000000   1.001061   -1.0  -1.000  0.000   1.000    1.0\n",
      "\n",
      "[74 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df.describe().T)  #Values need to be normalized before fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1         0\n",
      "F2         0\n",
      "F3         0\n",
      "F4         0\n",
      "F5         0\n",
      "          ..\n",
      "F70        0\n",
      "F71        0\n",
      "F72        0\n",
      "Valence    0\n",
      "Arousal    0\n",
      "Length: 74, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1         float64\n",
      "F2         float64\n",
      "F3         float64\n",
      "F4         float64\n",
      "F5         float64\n",
      "            ...   \n",
      "F70        float64\n",
      "F71        float64\n",
      "F72        float64\n",
      "Valence    float64\n",
      "Arousal    float64\n",
      "Length: 74, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(labels = [\"Valence\", \"Arousal\"], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Scaling the inputs\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(X)\n",
    "\n",
    "# min_max=MinMaxScaler()\n",
    "# # X_train=X_test=min_max.fit_transform(X)\n",
    "# print(min_max.fit(X))\n",
    "# # min_max.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43133047, 0.71170707, 0.22662266, ..., 0.38939394, 0.3293578 ,\n",
       "        0.22159468],\n",
       "       [0.47049356, 0.81021145, 0.39713971, ..., 0.39090909, 0.37553517,\n",
       "        0.48568106],\n",
       "       [0.23079399, 0.44816916, 0.24752475, ..., 0.78212121, 0.72721713,\n",
       "        0.6013289 ],\n",
       "       ...,\n",
       "       [0.12821888, 0.25941207, 0.13586359, ..., 0.66606061, 0.58012232,\n",
       "        0.44385382],\n",
       "       [0.25482833, 0.5337803 , 0.33873487, ..., 0.53      , 0.48868502,\n",
       "        0.43355482],\n",
       "       [0.07349785, 0.15162455, 0.02420242, ..., 0.62018182, 0.64159021,\n",
       "        0.63222591]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_test=scaled\n",
    "yval_train=yval_test=df['Valence'] #train entire valence dataframe\n",
    "yaro_train=yaro_test=df['Arousal'] #train entire arousal dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43133047, 0.71170707, 0.22662266, ..., 0.38939394, 0.3293578 ,\n",
       "        0.22159468],\n",
       "       [0.47049356, 0.81021145, 0.39713971, ..., 0.39090909, 0.37553517,\n",
       "        0.48568106],\n",
       "       [0.23079399, 0.44816916, 0.24752475, ..., 0.78212121, 0.72721713,\n",
       "        0.6013289 ],\n",
       "       ...,\n",
       "       [0.12821888, 0.25941207, 0.13586359, ..., 0.66606061, 0.58012232,\n",
       "        0.44385382],\n",
       "       [0.25482833, 0.5337803 , 0.33873487, ..., 0.53      , 0.48868502,\n",
       "        0.43355482],\n",
       "       [0.07349785, 0.15162455, 0.02420242, ..., 0.62018182, 0.64159021,\n",
       "        0.63222591]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        F1     F2      F3    F4      F5     F6      F7     F8     F9     F10  \\\n",
      "0    45.00  66.10 -20.600 -36.5   -8.25 -13.60   7.570 -10.50 -45.20  -53.00   \n",
      "1    52.30  85.20  10.400  19.5  -25.40 -27.70  -8.100   4.32  15.20    8.46   \n",
      "2     7.62  15.00 -16.800 -20.8  135.00  65.20 -16.800  -2.30  10.00    6.02   \n",
      "3    -5.88  -8.53 -26.500 -39.0  -34.90 -44.80 -40.700 -38.90  20.80   64.70   \n",
      "4     3.23   9.13 -13.200 -18.7  -30.10 -33.20   2.850  20.30  10.90  -13.70   \n",
      "..     ...    ...     ...   ...     ...    ...     ...    ...    ...     ...   \n",
      "467 -19.30 -35.30 -24.200 -26.8   41.60  56.90 -67.600 -53.60  45.40  122.00   \n",
      "468  -1.22   4.58  66.700  89.8   47.30  61.10  -2.030  22.50  21.50   10.20   \n",
      "469 -11.50 -21.60 -37.100 -56.0  -13.30 -13.20  -2.230 -11.20  -6.36    6.61   \n",
      "470  12.10  31.60  -0.218  13.7    2.91  15.70   1.360  20.10  32.00   40.40   \n",
      "471 -21.70 -42.50 -57.400 -91.6   -2.32   5.57  -0.428  13.00  15.40   39.50   \n",
      "\n",
      "     ...    F63    F64    F65    F66      F67    F68      F69    F70    F71  \\\n",
      "0    ...  -6.55 -13.00 -15.90 -26.20  25.4000   4.89 -45.5000 -71.50 -70.30   \n",
      "1    ...   1.06   3.09 -11.50 -16.40  22.5000  36.30 -18.1000 -71.00 -55.20   \n",
      "2    ...  -3.95  -5.18  -1.33   9.78 -28.9000 -18.30  23.7000  58.10  59.80   \n",
      "3    ... -13.40 -30.10   3.66  17.60  -0.0467  -3.93  -1.0700  15.80  33.10   \n",
      "4    ...  -3.48 -11.50   7.49  17.20 -15.9000  -5.11  25.7000  53.20  64.20   \n",
      "..   ...    ...    ...    ...    ...      ...    ...      ...    ...    ...   \n",
      "467  ...   5.26  12.50 -24.20 -46.40 -25.8000 -39.00 -44.8000 -31.50  -7.66   \n",
      "468  ...  -7.02 -13.60  -2.49   9.09  21.8000  -5.08 -16.9000  22.20  81.20   \n",
      "469  ...   7.01  13.60  -5.06  -3.83 -28.8000 -23.00  -0.0406  19.80  11.70   \n",
      "470  ...   1.49   5.94   5.20  13.80  11.4000   1.34 -21.9000 -25.10 -18.20   \n",
      "471  ...  -3.71  -9.02 -18.70 -31.10  -7.2400  -0.62  -7.3400   4.66  31.80   \n",
      "\n",
      "        F72  \n",
      "0    -77.30  \n",
      "1      2.19  \n",
      "2     37.00  \n",
      "3     34.30  \n",
      "4     69.40  \n",
      "..      ...  \n",
      "467   22.90  \n",
      "468  101.00  \n",
      "469  -10.40  \n",
      "470  -13.50  \n",
      "471   46.30  \n",
      "\n",
      "[472 rows x 72 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Y_val =df[\"Valence\"].values\n",
    "Y_aro =df[\"Arousal\"].values\n",
    "# Encoding categorical data\n",
    "# labelencoder = LabelEncoder()\n",
    "# Y_val = labelencoder.fit_transform(Y_val) \n",
    "# Y_aro = labelencoder.fit_transform(Y_aro) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,\n",
       "        1.,  1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
       "       -1., -1., -1., -1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_aro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472, 72)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# unique_elements, counts_elements = np.unique(y_train, return_counts=True)\n",
    "# print(np.asarray((unique_elements, counts_elements)))\n",
    "####################################################################\n",
    "# Over-Complex network\n",
    "# More complex than needed \n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(128, input_dim=30, activation='relu')) \n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(32))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(8))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(4))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1)) \n",
    "# model.add(Activation('sigmoid'))  \n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',             #also try adam\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Complex network\n",
    "# Still complex but may work...\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(16, input_dim=30, activation='relu')) \n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(16))\n",
    "# model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1)) \n",
    "# model.add(Activation('sigmoid'))  \n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',             #also try adam\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# print(model.summary())\n",
    "####################################################################\n",
    "#Simple network 1\n",
    "# Appropriate architecture for the challenge\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(16, input_dim=30, activation='relu')) \n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(1)) \n",
    "# model.add(Activation('sigmoid'))  \n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',             #also try adam\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# #model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                1168      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 2         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,187\n",
      "Trainable params: 1,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Simple network 2\n",
    "# Too simple??\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=72, activation='relu')) \n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(1)) \n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(1)) \n",
    "model.add(Activation('sigmoid'))  \n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',             #also try adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 111ms/step - loss: 193.7829 - accuracy: 0.2521 - val_loss: 172.3372 - val_accuracy: 0.2500\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 161.8384 - accuracy: 0.2521 - val_loss: 139.3701 - val_accuracy: 0.2500\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 126.7234 - accuracy: 0.2627 - val_loss: 106.4801 - val_accuracy: 0.2542\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 95.7020 - accuracy: 0.2860 - val_loss: 75.0479 - val_accuracy: 0.3072\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 63.1132 - accuracy: 0.3284 - val_loss: 46.8105 - val_accuracy: 0.3644\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 39.4151 - accuracy: 0.3877 - val_loss: 27.0312 - val_accuracy: 0.4788\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 25.5205 - accuracy: 0.4958 - val_loss: 20.5671 - val_accuracy: 0.5403\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 21.8513 - accuracy: 0.5826 - val_loss: 20.8111 - val_accuracy: 0.6102\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 21.8784 - accuracy: 0.6102 - val_loss: 20.6420 - val_accuracy: 0.6504\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 21.1235 - accuracy: 0.6504 - val_loss: 18.6860 - val_accuracy: 0.6780\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 18.5758 - accuracy: 0.6758 - val_loss: 15.2308 - val_accuracy: 0.6822\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 15.1694 - accuracy: 0.6780 - val_loss: 11.6395 - val_accuracy: 0.6737\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 11.7493 - accuracy: 0.6674 - val_loss: 9.1266 - val_accuracy: 0.6653\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 10.3896 - accuracy: 0.6610 - val_loss: 8.2967 - val_accuracy: 0.6483\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 8.6504 - accuracy: 0.6610 - val_loss: 7.6528 - val_accuracy: 0.6737\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 9.2617 - accuracy: 0.6801 - val_loss: 6.5604 - val_accuracy: 0.6907\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 7.5213 - accuracy: 0.6843 - val_loss: 5.6075 - val_accuracy: 0.7140\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.9040 - accuracy: 0.7097 - val_loss: 5.0474 - val_accuracy: 0.7309\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 6.2317 - accuracy: 0.7288 - val_loss: 4.6774 - val_accuracy: 0.7394\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 6.6819 - accuracy: 0.7119 - val_loss: 4.2175 - val_accuracy: 0.7331\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 5.9651 - accuracy: 0.7182 - val_loss: 3.8353 - val_accuracy: 0.7415\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 4.9219 - accuracy: 0.7373 - val_loss: 3.6001 - val_accuracy: 0.7394\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.0969 - accuracy: 0.7415 - val_loss: 3.3405 - val_accuracy: 0.7415\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 4.3432 - accuracy: 0.7288 - val_loss: 3.1083 - val_accuracy: 0.7606\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.4452 - accuracy: 0.7521 - val_loss: 2.9871 - val_accuracy: 0.7712\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.5542 - accuracy: 0.7564 - val_loss: 2.8513 - val_accuracy: 0.7754\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.3477 - accuracy: 0.7754 - val_loss: 2.7020 - val_accuracy: 0.7839\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 4.5581 - accuracy: 0.7775 - val_loss: 2.6158 - val_accuracy: 0.7860\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.4799 - accuracy: 0.7691 - val_loss: 2.5268 - val_accuracy: 0.7966\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 4.7870 - accuracy: 0.7712 - val_loss: 2.4187 - val_accuracy: 0.7860\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.8345 - accuracy: 0.7733 - val_loss: 2.3699 - val_accuracy: 0.7860\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.8490 - accuracy: 0.7691 - val_loss: 2.2556 - val_accuracy: 0.8030\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.2176 - accuracy: 0.7903 - val_loss: 2.2182 - val_accuracy: 0.8008\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.6419 - accuracy: 0.7903 - val_loss: 2.1197 - val_accuracy: 0.8072\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.3286 - accuracy: 0.7733 - val_loss: 2.0858 - val_accuracy: 0.8051\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.5524 - accuracy: 0.7945 - val_loss: 2.0168 - val_accuracy: 0.8178\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 3.2313 - accuracy: 0.7691 - val_loss: 1.9714 - val_accuracy: 0.8114\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.6367 - accuracy: 0.8008 - val_loss: 1.9231 - val_accuracy: 0.8114\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.6293 - accuracy: 0.8030 - val_loss: 1.8859 - val_accuracy: 0.8220\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.2416 - accuracy: 0.8136 - val_loss: 1.8416 - val_accuracy: 0.8199\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 37ms/step - loss: 3.6013 - accuracy: 0.7987 - val_loss: 1.7959 - val_accuracy: 0.8199\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.8371 - accuracy: 0.7945 - val_loss: 1.7689 - val_accuracy: 0.8220\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.3787 - accuracy: 0.8220 - val_loss: 1.7245 - val_accuracy: 0.8220\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.9712 - accuracy: 0.8178 - val_loss: 1.6937 - val_accuracy: 0.8263\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.7285 - accuracy: 0.8136 - val_loss: 1.6802 - val_accuracy: 0.8305\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.9938 - accuracy: 0.8093 - val_loss: 1.6366 - val_accuracy: 0.8263\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 2.5468 - accuracy: 0.7924 - val_loss: 1.6042 - val_accuracy: 0.8242\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.9270 - accuracy: 0.7924 - val_loss: 1.5708 - val_accuracy: 0.8242\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.5524 - accuracy: 0.7903 - val_loss: 1.5443 - val_accuracy: 0.8326\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 2.1641 - accuracy: 0.7987 - val_loss: 1.5297 - val_accuracy: 0.8199\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 3.4526 - accuracy: 0.7775 - val_loss: 1.4898 - val_accuracy: 0.8347\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.8632 - accuracy: 0.8242 - val_loss: 1.4716 - val_accuracy: 0.8305\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.2466 - accuracy: 0.8072 - val_loss: 1.4404 - val_accuracy: 0.8242\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.2291 - accuracy: 0.8199 - val_loss: 1.4543 - val_accuracy: 0.8263\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.5122 - accuracy: 0.7839 - val_loss: 1.3901 - val_accuracy: 0.8347\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.9229 - accuracy: 0.8030 - val_loss: 1.3725 - val_accuracy: 0.8347\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.3456 - accuracy: 0.8093 - val_loss: 1.3687 - val_accuracy: 0.8305\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.6612 - accuracy: 0.8242 - val_loss: 1.3289 - val_accuracy: 0.8242\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 2.4344 - accuracy: 0.8008 - val_loss: 1.3370 - val_accuracy: 0.8284\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.4949 - accuracy: 0.8220 - val_loss: 1.3242 - val_accuracy: 0.8284\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.9106 - accuracy: 0.8220 - val_loss: 1.2778 - val_accuracy: 0.8369\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.7958 - accuracy: 0.8199 - val_loss: 1.3254 - val_accuracy: 0.8263\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.7471 - accuracy: 0.8157 - val_loss: 1.2364 - val_accuracy: 0.8390\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.4386 - accuracy: 0.8157 - val_loss: 1.3470 - val_accuracy: 0.8242\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.7458 - accuracy: 0.7966 - val_loss: 1.1971 - val_accuracy: 0.8432\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1798 - accuracy: 0.8199 - val_loss: 1.2702 - val_accuracy: 0.8284\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.7453 - accuracy: 0.8199 - val_loss: 1.2279 - val_accuracy: 0.8347\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.1881 - accuracy: 0.8157 - val_loss: 1.1589 - val_accuracy: 0.8411\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.1693 - accuracy: 0.8093 - val_loss: 1.1977 - val_accuracy: 0.8432\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.5642 - accuracy: 0.8114 - val_loss: 1.1133 - val_accuracy: 0.8496\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.4329 - accuracy: 0.8199 - val_loss: 1.0934 - val_accuracy: 0.8453\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3728 - accuracy: 0.8263 - val_loss: 1.0933 - val_accuracy: 0.8453\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.7985 - accuracy: 0.8157 - val_loss: 1.0609 - val_accuracy: 0.8496\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.2196 - accuracy: 0.8305 - val_loss: 1.0578 - val_accuracy: 0.8369\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.4157 - accuracy: 0.8114 - val_loss: 1.0086 - val_accuracy: 0.8411\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.0421 - accuracy: 0.8305 - val_loss: 0.9866 - val_accuracy: 0.8496\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.5575 - accuracy: 0.8157 - val_loss: 0.9625 - val_accuracy: 0.8475\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.2999 - accuracy: 0.8305 - val_loss: 0.9408 - val_accuracy: 0.8581\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.9430 - accuracy: 0.8220 - val_loss: 0.9496 - val_accuracy: 0.8475\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.5887 - accuracy: 0.8199 - val_loss: 0.9133 - val_accuracy: 0.8538\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.5718 - accuracy: 0.8453 - val_loss: 0.9036 - val_accuracy: 0.8453\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.7819 - accuracy: 0.8347 - val_loss: 0.8727 - val_accuracy: 0.8602\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2.0086 - accuracy: 0.8305 - val_loss: 0.8602 - val_accuracy: 0.8623\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3108 - accuracy: 0.8517 - val_loss: 0.8444 - val_accuracy: 0.8623\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3504 - accuracy: 0.8369 - val_loss: 0.8330 - val_accuracy: 0.8538\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.9876 - accuracy: 0.8284 - val_loss: 0.8248 - val_accuracy: 0.8517\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.9477 - accuracy: 0.8157 - val_loss: 0.8058 - val_accuracy: 0.8559\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.9281 - accuracy: 0.8347 - val_loss: 0.7872 - val_accuracy: 0.8538\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.2245 - accuracy: 0.8114 - val_loss: 0.7780 - val_accuracy: 0.8475\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.6963 - accuracy: 0.8199 - val_loss: 0.7610 - val_accuracy: 0.8496\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4897 - accuracy: 0.8347 - val_loss: 0.7550 - val_accuracy: 0.8453\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3975 - accuracy: 0.8263 - val_loss: 0.7216 - val_accuracy: 0.8581\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4847 - accuracy: 0.8390 - val_loss: 0.7086 - val_accuracy: 0.8517\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.8447 - accuracy: 0.8326 - val_loss: 0.6999 - val_accuracy: 0.8581\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1178 - accuracy: 0.8411 - val_loss: 0.6809 - val_accuracy: 0.8538\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.5574 - accuracy: 0.8369 - val_loss: 0.6653 - val_accuracy: 0.8559\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.4115 - accuracy: 0.8326 - val_loss: 0.6506 - val_accuracy: 0.8517\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.7636 - accuracy: 0.8432 - val_loss: 0.6465 - val_accuracy: 0.8581\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2.3313 - accuracy: 0.8178 - val_loss: 0.6307 - val_accuracy: 0.8644\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5353 - accuracy: 0.8432 - val_loss: 0.6172 - val_accuracy: 0.8538\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2133 - accuracy: 0.8475 - val_loss: 0.6131 - val_accuracy: 0.8665\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.6477 - accuracy: 0.8369 - val_loss: 0.6102 - val_accuracy: 0.8686\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1609 - accuracy: 0.8432 - val_loss: 0.6145 - val_accuracy: 0.8708\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3682 - accuracy: 0.8475 - val_loss: 0.5745 - val_accuracy: 0.8686\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.7834 - accuracy: 0.8326 - val_loss: 0.5867 - val_accuracy: 0.8835\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.0474 - accuracy: 0.8453 - val_loss: 0.6181 - val_accuracy: 0.8559\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4139 - accuracy: 0.8517 - val_loss: 0.5693 - val_accuracy: 0.8814\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8916 - accuracy: 0.8750 - val_loss: 0.5354 - val_accuracy: 0.8771\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4921 - accuracy: 0.8644 - val_loss: 0.5247 - val_accuracy: 0.8750\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5568 - accuracy: 0.8411 - val_loss: 0.5118 - val_accuracy: 0.8729\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2551 - accuracy: 0.8496 - val_loss: 0.5006 - val_accuracy: 0.8814\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.8411 - accuracy: 0.8623 - val_loss: 0.4956 - val_accuracy: 0.8877\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9962 - accuracy: 0.8814 - val_loss: 0.4919 - val_accuracy: 0.8898\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.3255 - accuracy: 0.8644 - val_loss: 0.4807 - val_accuracy: 0.8919\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2101 - accuracy: 0.8771 - val_loss: 0.4712 - val_accuracy: 0.8941\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.2802 - accuracy: 0.8665 - val_loss: 0.4621 - val_accuracy: 0.8941\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.4238 - accuracy: 0.8665 - val_loss: 0.4571 - val_accuracy: 0.8919\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0616 - accuracy: 0.8686 - val_loss: 0.4494 - val_accuracy: 0.9047\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1224 - accuracy: 0.8665 - val_loss: 0.4502 - val_accuracy: 0.8941\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5045 - accuracy: 0.8538 - val_loss: 0.4470 - val_accuracy: 0.8877\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2114 - accuracy: 0.8835 - val_loss: 0.4666 - val_accuracy: 0.8856\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8394 - accuracy: 0.8623 - val_loss: 0.4394 - val_accuracy: 0.8898\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1277 - accuracy: 0.8665 - val_loss: 0.4171 - val_accuracy: 0.9131\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.4213 - accuracy: 0.8792 - val_loss: 0.4230 - val_accuracy: 0.9089\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2497 - accuracy: 0.8814 - val_loss: 0.4097 - val_accuracy: 0.9089\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0163 - accuracy: 0.8814 - val_loss: 0.4061 - val_accuracy: 0.9110\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0677 - accuracy: 0.8686 - val_loss: 0.4066 - val_accuracy: 0.9025\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9132 - accuracy: 0.9025 - val_loss: 0.4101 - val_accuracy: 0.9110\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5687 - accuracy: 0.8877 - val_loss: 0.4294 - val_accuracy: 0.8814\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5718 - accuracy: 0.8623 - val_loss: 0.4156 - val_accuracy: 0.9047\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5029 - accuracy: 0.8750 - val_loss: 0.3879 - val_accuracy: 0.9153\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.3267 - accuracy: 0.8602 - val_loss: 0.3929 - val_accuracy: 0.8983\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2465 - accuracy: 0.8856 - val_loss: 0.4265 - val_accuracy: 0.8962\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1536 - accuracy: 0.8941 - val_loss: 0.4092 - val_accuracy: 0.8898\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0834 - accuracy: 0.8623 - val_loss: 0.3812 - val_accuracy: 0.9025\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1979 - accuracy: 0.8856 - val_loss: 0.3840 - val_accuracy: 0.9089\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1733 - accuracy: 0.8792 - val_loss: 0.4027 - val_accuracy: 0.9004\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 1.2377 - accuracy: 0.8729 - val_loss: 0.3718 - val_accuracy: 0.9110\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0932 - accuracy: 0.8835 - val_loss: 0.3662 - val_accuracy: 0.9025\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0270 - accuracy: 0.8602 - val_loss: 0.3616 - val_accuracy: 0.9089\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.2225 - accuracy: 0.8771 - val_loss: 0.3784 - val_accuracy: 0.9025\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9665 - accuracy: 0.8729 - val_loss: 0.3934 - val_accuracy: 0.9004\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.1374 - accuracy: 0.8771 - val_loss: 0.3582 - val_accuracy: 0.9110\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8087 - accuracy: 0.8665 - val_loss: 0.3447 - val_accuracy: 0.9216\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8904 - accuracy: 0.8792 - val_loss: 0.3719 - val_accuracy: 0.8919\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0267 - accuracy: 0.8877 - val_loss: 0.3457 - val_accuracy: 0.9174\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9924 - accuracy: 0.8877 - val_loss: 0.3463 - val_accuracy: 0.9174\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.4232 - accuracy: 0.8814 - val_loss: 0.3336 - val_accuracy: 0.9237\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1825 - accuracy: 0.8983 - val_loss: 0.3322 - val_accuracy: 0.9216\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1290 - accuracy: 0.8941 - val_loss: 0.3306 - val_accuracy: 0.9216\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1571 - accuracy: 0.8750 - val_loss: 0.3353 - val_accuracy: 0.9174\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.7795 - accuracy: 0.8856 - val_loss: 0.3460 - val_accuracy: 0.9047\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.9114 - accuracy: 0.8792 - val_loss: 0.3281 - val_accuracy: 0.9195\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.8286 - accuracy: 0.8941 - val_loss: 0.3146 - val_accuracy: 0.9216\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1927 - accuracy: 0.8792 - val_loss: 0.3169 - val_accuracy: 0.9131\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8659 - accuracy: 0.8856 - val_loss: 0.3036 - val_accuracy: 0.9131\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 36ms/step - loss: 0.9563 - accuracy: 0.8919 - val_loss: 0.3010 - val_accuracy: 0.9195\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.4121 - accuracy: 0.8941 - val_loss: 0.3024 - val_accuracy: 0.9258\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.0864 - accuracy: 0.8708 - val_loss: 0.3137 - val_accuracy: 0.9089\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6783 - accuracy: 0.8877 - val_loss: 0.2995 - val_accuracy: 0.9216\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9151 - accuracy: 0.9025 - val_loss: 0.3116 - val_accuracy: 0.9131\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3399 - accuracy: 0.8898 - val_loss: 0.2994 - val_accuracy: 0.9280\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7390 - accuracy: 0.9004 - val_loss: 0.2966 - val_accuracy: 0.9195\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9918 - accuracy: 0.8856 - val_loss: 0.2861 - val_accuracy: 0.9280\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.2189 - accuracy: 0.8750 - val_loss: 0.2823 - val_accuracy: 0.9216\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9695 - accuracy: 0.8771 - val_loss: 0.3091 - val_accuracy: 0.9131\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0793 - accuracy: 0.8750 - val_loss: 0.3137 - val_accuracy: 0.9068\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.8500 - accuracy: 0.8771 - val_loss: 0.2770 - val_accuracy: 0.9110\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0858 - accuracy: 0.8919 - val_loss: 0.2746 - val_accuracy: 0.9153\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5899 - accuracy: 0.8877 - val_loss: 0.2747 - val_accuracy: 0.9174\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.0357 - accuracy: 0.8941 - val_loss: 0.2682 - val_accuracy: 0.9195\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9789 - accuracy: 0.8983 - val_loss: 0.2610 - val_accuracy: 0.9258\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.0050 - accuracy: 0.9025 - val_loss: 0.2587 - val_accuracy: 0.9258\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.0067 - accuracy: 0.8941 - val_loss: 0.2572 - val_accuracy: 0.9280\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.1081 - accuracy: 0.9047 - val_loss: 0.2572 - val_accuracy: 0.9301\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1683 - accuracy: 0.8877 - val_loss: 0.2652 - val_accuracy: 0.9237\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7398 - accuracy: 0.9004 - val_loss: 0.2575 - val_accuracy: 0.9258\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6376 - accuracy: 0.8962 - val_loss: 0.2546 - val_accuracy: 0.9280\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9253 - accuracy: 0.9025 - val_loss: 0.2474 - val_accuracy: 0.9301\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7025 - accuracy: 0.9153 - val_loss: 0.2448 - val_accuracy: 0.9301\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6976 - accuracy: 0.9089 - val_loss: 0.2459 - val_accuracy: 0.9322\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.0841 - accuracy: 0.8962 - val_loss: 0.2449 - val_accuracy: 0.9258\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5641 - accuracy: 0.8962 - val_loss: 0.2403 - val_accuracy: 0.9237\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7183 - accuracy: 0.9025 - val_loss: 0.2387 - val_accuracy: 0.9280\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.1169 - accuracy: 0.8962 - val_loss: 0.2397 - val_accuracy: 0.9258\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1236 - accuracy: 0.9004 - val_loss: 0.2347 - val_accuracy: 0.9280\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9401 - accuracy: 0.9068 - val_loss: 0.2364 - val_accuracy: 0.9322\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7891 - accuracy: 0.9068 - val_loss: 0.2321 - val_accuracy: 0.9322\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9956 - accuracy: 0.9089 - val_loss: 0.2275 - val_accuracy: 0.9364\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7618 - accuracy: 0.9004 - val_loss: 0.2321 - val_accuracy: 0.9216\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6024 - accuracy: 0.8792 - val_loss: 0.2416 - val_accuracy: 0.9110\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8183 - accuracy: 0.8792 - val_loss: 0.2326 - val_accuracy: 0.9280\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 1.2202 - accuracy: 0.8750 - val_loss: 0.2258 - val_accuracy: 0.9258\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.5822 - accuracy: 0.8919 - val_loss: 0.2266 - val_accuracy: 0.9237\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6607 - accuracy: 0.8898 - val_loss: 0.2200 - val_accuracy: 0.9258\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.0482 - accuracy: 0.8941 - val_loss: 0.2264 - val_accuracy: 0.9237\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6427 - accuracy: 0.9025 - val_loss: 0.2222 - val_accuracy: 0.9195\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3904 - accuracy: 0.9068 - val_loss: 0.2255 - val_accuracy: 0.9195\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8830 - accuracy: 0.8983 - val_loss: 0.2174 - val_accuracy: 0.9237\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6277 - accuracy: 0.8983 - val_loss: 0.2114 - val_accuracy: 0.9280\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8137 - accuracy: 0.9110 - val_loss: 0.2085 - val_accuracy: 0.9258\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8813 - accuracy: 0.9153 - val_loss: 0.2380 - val_accuracy: 0.9195\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8510 - accuracy: 0.9025 - val_loss: 0.2388 - val_accuracy: 0.9110\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7190 - accuracy: 0.8814 - val_loss: 0.2026 - val_accuracy: 0.9322\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9790 - accuracy: 0.9068 - val_loss: 0.2564 - val_accuracy: 0.9216\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7510 - accuracy: 0.8814 - val_loss: 0.2069 - val_accuracy: 0.9280\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6225 - accuracy: 0.9110 - val_loss: 0.2015 - val_accuracy: 0.9322\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6254 - accuracy: 0.9025 - val_loss: 0.1970 - val_accuracy: 0.9322\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5926 - accuracy: 0.9237 - val_loss: 0.1891 - val_accuracy: 0.9407\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.4070 - accuracy: 0.9174 - val_loss: 0.1865 - val_accuracy: 0.9386\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6278 - accuracy: 0.9068 - val_loss: 0.1859 - val_accuracy: 0.9428\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4559 - accuracy: 0.9237 - val_loss: 0.1914 - val_accuracy: 0.9343\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.7501 - accuracy: 0.9025 - val_loss: 0.2066 - val_accuracy: 0.9258\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5952 - accuracy: 0.9089 - val_loss: 0.1856 - val_accuracy: 0.9364\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5050 - accuracy: 0.9089 - val_loss: 0.1997 - val_accuracy: 0.9301\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2155 - accuracy: 0.8835 - val_loss: 0.1816 - val_accuracy: 0.9343\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6736 - accuracy: 0.9025 - val_loss: 0.1801 - val_accuracy: 0.9322\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6245 - accuracy: 0.9131 - val_loss: 0.2160 - val_accuracy: 0.9216\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6426 - accuracy: 0.8962 - val_loss: 0.1999 - val_accuracy: 0.9216\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5829 - accuracy: 0.8919 - val_loss: 0.1648 - val_accuracy: 0.9407\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7290 - accuracy: 0.9025 - val_loss: 0.1944 - val_accuracy: 0.9280\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6715 - accuracy: 0.8898 - val_loss: 0.1842 - val_accuracy: 0.9386\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6700 - accuracy: 0.9068 - val_loss: 0.1729 - val_accuracy: 0.9407\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5833 - accuracy: 0.9216 - val_loss: 0.1585 - val_accuracy: 0.9364\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4082 - accuracy: 0.9237 - val_loss: 0.1549 - val_accuracy: 0.9407\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8178 - accuracy: 0.9004 - val_loss: 0.1594 - val_accuracy: 0.9449\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6451 - accuracy: 0.9174 - val_loss: 0.1532 - val_accuracy: 0.9407\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.6834 - accuracy: 0.9216 - val_loss: 0.1497 - val_accuracy: 0.9470\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5080 - accuracy: 0.9216 - val_loss: 0.1643 - val_accuracy: 0.9343\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8006 - accuracy: 0.9089 - val_loss: 0.1582 - val_accuracy: 0.9428\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 33ms/step - loss: 0.4669 - accuracy: 0.9153 - val_loss: 0.1460 - val_accuracy: 0.9492\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6338 - accuracy: 0.9301 - val_loss: 0.1540 - val_accuracy: 0.9470\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8229 - accuracy: 0.8983 - val_loss: 0.1632 - val_accuracy: 0.9386\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7019 - accuracy: 0.9174 - val_loss: 0.1611 - val_accuracy: 0.9407\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6018 - accuracy: 0.9216 - val_loss: 0.1445 - val_accuracy: 0.9576\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3347 - accuracy: 0.9322 - val_loss: 0.1405 - val_accuracy: 0.9513\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4382 - accuracy: 0.9174 - val_loss: 0.1339 - val_accuracy: 0.9492\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8240 - accuracy: 0.9025 - val_loss: 0.1332 - val_accuracy: 0.9492\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7446 - accuracy: 0.9174 - val_loss: 0.1350 - val_accuracy: 0.9428\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3348 - accuracy: 0.9089 - val_loss: 0.1344 - val_accuracy: 0.9428\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5275 - accuracy: 0.9301 - val_loss: 0.1423 - val_accuracy: 0.9449\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5177 - accuracy: 0.9174 - val_loss: 0.1756 - val_accuracy: 0.9343\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5744 - accuracy: 0.9025 - val_loss: 0.1359 - val_accuracy: 0.9470\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3560 - accuracy: 0.9174 - val_loss: 0.1338 - val_accuracy: 0.9470\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4932 - accuracy: 0.9258 - val_loss: 0.1284 - val_accuracy: 0.9470\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4445 - accuracy: 0.9110 - val_loss: 0.1461 - val_accuracy: 0.9386\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6396 - accuracy: 0.9025 - val_loss: 0.1774 - val_accuracy: 0.9386\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5961 - accuracy: 0.9131 - val_loss: 0.1302 - val_accuracy: 0.9470\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6074 - accuracy: 0.9153 - val_loss: 0.1193 - val_accuracy: 0.9534\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5075 - accuracy: 0.9237 - val_loss: 0.1351 - val_accuracy: 0.9492\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.6251 - accuracy: 0.9195 - val_loss: 0.1190 - val_accuracy: 0.9534\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5471 - accuracy: 0.9153 - val_loss: 0.1242 - val_accuracy: 0.9534\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5787 - accuracy: 0.9153 - val_loss: 0.1353 - val_accuracy: 0.9619\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5085 - accuracy: 0.9237 - val_loss: 0.1336 - val_accuracy: 0.9513\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5901 - accuracy: 0.9237 - val_loss: 0.1576 - val_accuracy: 0.9470\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3145 - accuracy: 0.9153 - val_loss: 0.1180 - val_accuracy: 0.9555\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4702 - accuracy: 0.9174 - val_loss: 0.1317 - val_accuracy: 0.9407\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5631 - accuracy: 0.9195 - val_loss: 0.1539 - val_accuracy: 0.9343\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7288 - accuracy: 0.9110 - val_loss: 0.1351 - val_accuracy: 0.9428\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.8309 - accuracy: 0.8983 - val_loss: 0.1154 - val_accuracy: 0.9534\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3778 - accuracy: 0.9237 - val_loss: 0.1316 - val_accuracy: 0.9576\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7717 - accuracy: 0.9131 - val_loss: 0.1432 - val_accuracy: 0.9407\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.5880 - accuracy: 0.8983 - val_loss: 0.1532 - val_accuracy: 0.9470\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.6006 - accuracy: 0.9343 - val_loss: 0.1172 - val_accuracy: 0.9597\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.3666 - accuracy: 0.9301 - val_loss: 0.1127 - val_accuracy: 0.9619\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5305 - accuracy: 0.9216 - val_loss: 0.1082 - val_accuracy: 0.9619\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2163 - accuracy: 0.9364 - val_loss: 0.1094 - val_accuracy: 0.9640\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.5243 - accuracy: 0.9216 - val_loss: 0.1231 - val_accuracy: 0.9619\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6434 - accuracy: 0.9216 - val_loss: 0.1210 - val_accuracy: 0.9513\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3041 - accuracy: 0.9322 - val_loss: 0.1031 - val_accuracy: 0.9640\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3273 - accuracy: 0.9449 - val_loss: 0.0978 - val_accuracy: 0.9682\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5434 - accuracy: 0.9258 - val_loss: 0.1018 - val_accuracy: 0.9597\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4379 - accuracy: 0.9322 - val_loss: 0.1159 - val_accuracy: 0.9640\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3630 - accuracy: 0.9513 - val_loss: 0.0947 - val_accuracy: 0.9682\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5290 - accuracy: 0.9237 - val_loss: 0.0981 - val_accuracy: 0.9597\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3758 - accuracy: 0.9386 - val_loss: 0.1034 - val_accuracy: 0.9661\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4269 - accuracy: 0.9428 - val_loss: 0.0911 - val_accuracy: 0.9703\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4041 - accuracy: 0.9364 - val_loss: 0.0933 - val_accuracy: 0.9640\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2479 - accuracy: 0.9513 - val_loss: 0.0928 - val_accuracy: 0.9725\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2355 - accuracy: 0.9576 - val_loss: 0.0869 - val_accuracy: 0.9703\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3335 - accuracy: 0.9386 - val_loss: 0.0862 - val_accuracy: 0.9619\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3585 - accuracy: 0.9343 - val_loss: 0.0968 - val_accuracy: 0.9725\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6511 - accuracy: 0.9322 - val_loss: 0.0886 - val_accuracy: 0.9661\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3534 - accuracy: 0.9301 - val_loss: 0.0810 - val_accuracy: 0.9703\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 30ms/step - loss: 0.3145 - accuracy: 0.9449 - val_loss: 0.0896 - val_accuracy: 0.9746\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.3332 - accuracy: 0.9470 - val_loss: 0.0823 - val_accuracy: 0.9682\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2706 - accuracy: 0.9343 - val_loss: 0.0822 - val_accuracy: 0.9703\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4645 - accuracy: 0.9407 - val_loss: 0.0793 - val_accuracy: 0.9746\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3050 - accuracy: 0.9407 - val_loss: 0.0897 - val_accuracy: 0.9640\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3108 - accuracy: 0.9428 - val_loss: 0.0834 - val_accuracy: 0.9746\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5642 - accuracy: 0.9301 - val_loss: 0.0801 - val_accuracy: 0.9661\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3148 - accuracy: 0.9449 - val_loss: 0.0794 - val_accuracy: 0.9767\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3211 - accuracy: 0.9301 - val_loss: 0.0812 - val_accuracy: 0.9703\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3527 - accuracy: 0.9449 - val_loss: 0.0784 - val_accuracy: 0.9725\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3016 - accuracy: 0.9513 - val_loss: 0.0780 - val_accuracy: 0.9703\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4432 - accuracy: 0.9364 - val_loss: 0.0754 - val_accuracy: 0.9725\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3983 - accuracy: 0.9258 - val_loss: 0.0727 - val_accuracy: 0.9746\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4204 - accuracy: 0.9534 - val_loss: 0.0733 - val_accuracy: 0.9746\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3348 - accuracy: 0.9492 - val_loss: 0.0713 - val_accuracy: 0.9788\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3078 - accuracy: 0.9534 - val_loss: 0.0734 - val_accuracy: 0.9746\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4417 - accuracy: 0.9470 - val_loss: 0.0664 - val_accuracy: 0.9831\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3900 - accuracy: 0.9555 - val_loss: 0.0735 - val_accuracy: 0.9746\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1604 - accuracy: 0.9492 - val_loss: 0.0740 - val_accuracy: 0.9809\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1932 - accuracy: 0.9619 - val_loss: 0.0718 - val_accuracy: 0.9788\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.5095 - accuracy: 0.9386 - val_loss: 0.0695 - val_accuracy: 0.9788\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5307 - accuracy: 0.9449 - val_loss: 0.0735 - val_accuracy: 0.9725\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4302 - accuracy: 0.9322 - val_loss: 0.0811 - val_accuracy: 0.9725\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5621 - accuracy: 0.9386 - val_loss: 0.0882 - val_accuracy: 0.9661\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4135 - accuracy: 0.9364 - val_loss: 0.0998 - val_accuracy: 0.9534\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2313 - accuracy: 0.9449 - val_loss: 0.0990 - val_accuracy: 0.9534\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3421 - accuracy: 0.9068 - val_loss: 0.0721 - val_accuracy: 0.9725\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4566 - accuracy: 0.9047 - val_loss: 0.1095 - val_accuracy: 0.9513\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4205 - accuracy: 0.9195 - val_loss: 0.1260 - val_accuracy: 0.9492\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3802 - accuracy: 0.9407 - val_loss: 0.0785 - val_accuracy: 0.9640\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3483 - accuracy: 0.9343 - val_loss: 0.0779 - val_accuracy: 0.9682\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2495 - accuracy: 0.9343 - val_loss: 0.0953 - val_accuracy: 0.9640\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3025 - accuracy: 0.9322 - val_loss: 0.0842 - val_accuracy: 0.9661\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1662 - accuracy: 0.9386 - val_loss: 0.0721 - val_accuracy: 0.9725\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3435 - accuracy: 0.9597 - val_loss: 0.0708 - val_accuracy: 0.9809\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1902 - accuracy: 0.9513 - val_loss: 0.0789 - val_accuracy: 0.9746\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3240 - accuracy: 0.9513 - val_loss: 0.0943 - val_accuracy: 0.9555\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3957 - accuracy: 0.9322 - val_loss: 0.0870 - val_accuracy: 0.9661\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3712 - accuracy: 0.9492 - val_loss: 0.0673 - val_accuracy: 0.9809\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3917 - accuracy: 0.9407 - val_loss: 0.0692 - val_accuracy: 0.9767\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2445 - accuracy: 0.9576 - val_loss: 0.0677 - val_accuracy: 0.9852\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3452 - accuracy: 0.9343 - val_loss: 0.0655 - val_accuracy: 0.9831\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2896 - accuracy: 0.9534 - val_loss: 0.0649 - val_accuracy: 0.9788\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2613 - accuracy: 0.9555 - val_loss: 0.0753 - val_accuracy: 0.9703\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3567 - accuracy: 0.9470 - val_loss: 0.0766 - val_accuracy: 0.9682\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3241 - accuracy: 0.9364 - val_loss: 0.0624 - val_accuracy: 0.9831\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2955 - accuracy: 0.9534 - val_loss: 0.0651 - val_accuracy: 0.9788\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2521 - accuracy: 0.9534 - val_loss: 0.0677 - val_accuracy: 0.9831\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1267 - accuracy: 0.9703 - val_loss: 0.0617 - val_accuracy: 0.9746\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2063 - accuracy: 0.9555 - val_loss: 0.0574 - val_accuracy: 0.9852\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1848 - accuracy: 0.9746 - val_loss: 0.0587 - val_accuracy: 0.9852\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1804 - accuracy: 0.9640 - val_loss: 0.0577 - val_accuracy: 0.9809\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2938 - accuracy: 0.9619 - val_loss: 0.0551 - val_accuracy: 0.9831\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2237 - accuracy: 0.9640 - val_loss: 0.0539 - val_accuracy: 0.9894\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1809 - accuracy: 0.9597 - val_loss: 0.0550 - val_accuracy: 0.9831\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3416 - accuracy: 0.9597 - val_loss: 0.0577 - val_accuracy: 0.9852\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2707 - accuracy: 0.9534 - val_loss: 0.0535 - val_accuracy: 0.9852\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2339 - accuracy: 0.9513 - val_loss: 0.0531 - val_accuracy: 0.9873\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2157 - accuracy: 0.9576 - val_loss: 0.0541 - val_accuracy: 0.9852\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2027 - accuracy: 0.9513 - val_loss: 0.0530 - val_accuracy: 0.9873\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0921 - accuracy: 0.9682 - val_loss: 0.0516 - val_accuracy: 0.9873\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2858 - accuracy: 0.9597 - val_loss: 0.0511 - val_accuracy: 0.9873\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1986 - accuracy: 0.9640 - val_loss: 0.0566 - val_accuracy: 0.9767\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3120 - accuracy: 0.9534 - val_loss: 0.0521 - val_accuracy: 0.9852\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5128 - accuracy: 0.9470 - val_loss: 0.0536 - val_accuracy: 0.9831\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1395 - accuracy: 0.9619 - val_loss: 0.0544 - val_accuracy: 0.9788\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2127 - accuracy: 0.9597 - val_loss: 0.0505 - val_accuracy: 0.9894\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2419 - accuracy: 0.9492 - val_loss: 0.0529 - val_accuracy: 0.9852\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1483 - accuracy: 0.9703 - val_loss: 0.0838 - val_accuracy: 0.9640\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2939 - accuracy: 0.9492 - val_loss: 0.0619 - val_accuracy: 0.9788\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.3581 - accuracy: 0.9386 - val_loss: 0.0603 - val_accuracy: 0.9809\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2537 - accuracy: 0.9492 - val_loss: 0.0577 - val_accuracy: 0.9873\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3419 - accuracy: 0.9534 - val_loss: 0.0527 - val_accuracy: 0.9852\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2144 - accuracy: 0.9619 - val_loss: 0.0509 - val_accuracy: 0.9894\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2504 - accuracy: 0.9619 - val_loss: 0.0514 - val_accuracy: 0.9894\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 35ms/step - loss: 0.3005 - accuracy: 0.9534 - val_loss: 0.0504 - val_accuracy: 0.9894\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1698 - accuracy: 0.9767 - val_loss: 0.0700 - val_accuracy: 0.9746\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1274 - accuracy: 0.9513 - val_loss: 0.0500 - val_accuracy: 0.9873\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3079 - accuracy: 0.9386 - val_loss: 0.0571 - val_accuracy: 0.9767\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.3415 - accuracy: 0.9597 - val_loss: 0.0437 - val_accuracy: 0.9915\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2127 - accuracy: 0.9682 - val_loss: 0.0450 - val_accuracy: 0.9915\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2633 - accuracy: 0.9703 - val_loss: 0.0452 - val_accuracy: 0.9915\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1474 - accuracy: 0.9725 - val_loss: 0.0442 - val_accuracy: 0.9936\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1764 - accuracy: 0.9746 - val_loss: 0.0438 - val_accuracy: 0.9915\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2176 - accuracy: 0.9576 - val_loss: 0.0433 - val_accuracy: 0.9936\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2009 - accuracy: 0.9725 - val_loss: 0.0440 - val_accuracy: 0.9936\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2504 - accuracy: 0.9703 - val_loss: 0.0441 - val_accuracy: 0.9915\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1850 - accuracy: 0.9619 - val_loss: 0.0450 - val_accuracy: 0.9894\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3904 - accuracy: 0.9597 - val_loss: 0.0486 - val_accuracy: 0.9894\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3990 - accuracy: 0.9513 - val_loss: 0.0480 - val_accuracy: 0.9894\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1983 - accuracy: 0.9725 - val_loss: 0.0490 - val_accuracy: 0.9873\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.2740 - accuracy: 0.9513 - val_loss: 0.0517 - val_accuracy: 0.9831\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 0.1569 - accuracy: 0.9682 - val_loss: 0.0470 - val_accuracy: 0.9873\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1979 - accuracy: 0.9492 - val_loss: 0.0495 - val_accuracy: 0.9831\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1512 - accuracy: 0.9619 - val_loss: 0.0454 - val_accuracy: 0.9894\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1060 - accuracy: 0.9682 - val_loss: 0.0437 - val_accuracy: 0.9894\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2620 - accuracy: 0.9661 - val_loss: 0.0586 - val_accuracy: 0.9767\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1209 - accuracy: 0.9661 - val_loss: 0.0440 - val_accuracy: 0.9894\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1440 - accuracy: 0.9746 - val_loss: 0.0441 - val_accuracy: 0.9894\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.4206 - accuracy: 0.9492 - val_loss: 0.0403 - val_accuracy: 0.9915\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3516 - accuracy: 0.9492 - val_loss: 0.0413 - val_accuracy: 0.9915\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1493 - accuracy: 0.9725 - val_loss: 0.0426 - val_accuracy: 0.9915\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2225 - accuracy: 0.9682 - val_loss: 0.0479 - val_accuracy: 0.9852\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1744 - accuracy: 0.9576 - val_loss: 0.0431 - val_accuracy: 0.9915\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1926 - accuracy: 0.9661 - val_loss: 0.0445 - val_accuracy: 0.9873\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3048 - accuracy: 0.9576 - val_loss: 0.0455 - val_accuracy: 0.9915\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1180 - accuracy: 0.9725 - val_loss: 0.0404 - val_accuracy: 0.9894\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1003 - accuracy: 0.9703 - val_loss: 0.0371 - val_accuracy: 0.9936\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3979 - accuracy: 0.9492 - val_loss: 0.0590 - val_accuracy: 0.9703\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 32ms/step - loss: 0.1184 - accuracy: 0.9619 - val_loss: 0.0552 - val_accuracy: 0.9746\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1289 - accuracy: 0.9597 - val_loss: 0.0407 - val_accuracy: 0.9873\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2079 - accuracy: 0.9597 - val_loss: 0.0632 - val_accuracy: 0.9725\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2578 - accuracy: 0.9470 - val_loss: 0.0503 - val_accuracy: 0.9767\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1811 - accuracy: 0.9513 - val_loss: 0.0341 - val_accuracy: 0.9915\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2769 - accuracy: 0.9534 - val_loss: 0.0461 - val_accuracy: 0.9873\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0838 - accuracy: 0.9703 - val_loss: 0.0463 - val_accuracy: 0.9831\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2069 - accuracy: 0.9619 - val_loss: 0.0368 - val_accuracy: 0.9936\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2290 - accuracy: 0.9661 - val_loss: 0.0379 - val_accuracy: 0.9915\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0797 - accuracy: 0.9852 - val_loss: 0.0389 - val_accuracy: 0.9873\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2898 - accuracy: 0.9619 - val_loss: 0.0354 - val_accuracy: 0.9915\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1856 - accuracy: 0.9597 - val_loss: 0.0332 - val_accuracy: 0.9979\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1319 - accuracy: 0.9767 - val_loss: 0.0348 - val_accuracy: 0.9958\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2368 - accuracy: 0.9640 - val_loss: 0.0398 - val_accuracy: 0.9873\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0985 - accuracy: 0.9703 - val_loss: 0.0371 - val_accuracy: 0.9894\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2027 - accuracy: 0.9597 - val_loss: 0.0490 - val_accuracy: 0.9767\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1919 - accuracy: 0.9597 - val_loss: 0.0502 - val_accuracy: 0.9767\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.2525 - accuracy: 0.9534 - val_loss: 0.0323 - val_accuracy: 0.9936\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.2745 - accuracy: 0.9470 - val_loss: 0.0509 - val_accuracy: 0.9746\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1529 - accuracy: 0.9513 - val_loss: 0.0370 - val_accuracy: 0.9873\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1991 - accuracy: 0.9470 - val_loss: 0.0320 - val_accuracy: 0.9915\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1778 - accuracy: 0.9767 - val_loss: 0.0338 - val_accuracy: 0.9958\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0807 - accuracy: 0.9746 - val_loss: 0.0325 - val_accuracy: 0.9936\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2698 - accuracy: 0.9576 - val_loss: 0.0387 - val_accuracy: 0.9831\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1650 - accuracy: 0.9703 - val_loss: 0.0334 - val_accuracy: 0.9915\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1664 - accuracy: 0.9725 - val_loss: 0.0291 - val_accuracy: 0.9958\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0824 - accuracy: 0.9767 - val_loss: 0.0281 - val_accuracy: 0.9958\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2161 - accuracy: 0.9746 - val_loss: 0.0373 - val_accuracy: 0.9894\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2726 - accuracy: 0.9513 - val_loss: 0.0269 - val_accuracy: 0.9958\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1097 - accuracy: 0.9703 - val_loss: 0.0305 - val_accuracy: 0.9936\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1768 - accuracy: 0.9661 - val_loss: 0.0341 - val_accuracy: 0.9894\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1605 - accuracy: 0.9619 - val_loss: 0.0312 - val_accuracy: 0.9958\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1214 - accuracy: 0.9619 - val_loss: 0.0364 - val_accuracy: 0.9873\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2511 - accuracy: 0.9492 - val_loss: 0.0377 - val_accuracy: 0.9831\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1811 - accuracy: 0.9597 - val_loss: 0.0357 - val_accuracy: 0.9873\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0802 - accuracy: 0.9661 - val_loss: 0.0323 - val_accuracy: 0.9936\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 43ms/step - loss: 0.1903 - accuracy: 0.9725 - val_loss: 0.0396 - val_accuracy: 0.9852\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1452 - accuracy: 0.9682 - val_loss: 0.0333 - val_accuracy: 0.9915\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1285 - accuracy: 0.9767 - val_loss: 0.0311 - val_accuracy: 0.9936\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1583 - accuracy: 0.9619 - val_loss: 0.0329 - val_accuracy: 0.9894\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1739 - accuracy: 0.9640 - val_loss: 0.0255 - val_accuracy: 0.9958\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1550 - accuracy: 0.9703 - val_loss: 0.0255 - val_accuracy: 0.9958\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1873 - accuracy: 0.9597 - val_loss: 0.0255 - val_accuracy: 0.9936\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1554 - accuracy: 0.9640 - val_loss: 0.0258 - val_accuracy: 0.9958\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0676 - accuracy: 0.9725 - val_loss: 0.0246 - val_accuracy: 0.9979\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1073 - accuracy: 0.9788 - val_loss: 0.0231 - val_accuracy: 0.9979\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0968 - accuracy: 0.9746 - val_loss: 0.0280 - val_accuracy: 0.9915\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2147 - accuracy: 0.9661 - val_loss: 0.0246 - val_accuracy: 0.9979\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1186 - accuracy: 0.9725 - val_loss: 0.0330 - val_accuracy: 0.9915\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0999 - accuracy: 0.9661 - val_loss: 0.0236 - val_accuracy: 0.9936\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1313 - accuracy: 0.9788 - val_loss: 0.0273 - val_accuracy: 0.9936\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2155 - accuracy: 0.9640 - val_loss: 0.0242 - val_accuracy: 0.9979\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0797 - accuracy: 0.9725 - val_loss: 0.0245 - val_accuracy: 0.9979\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0977 - accuracy: 0.9809 - val_loss: 0.0264 - val_accuracy: 0.9936\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1131 - accuracy: 0.9746 - val_loss: 0.0288 - val_accuracy: 0.9979\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1971 - accuracy: 0.9682 - val_loss: 0.0257 - val_accuracy: 0.9958\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1113 - accuracy: 0.9640 - val_loss: 0.0249 - val_accuracy: 0.9979\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1036 - accuracy: 0.9746 - val_loss: 0.0267 - val_accuracy: 0.9979\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2472 - accuracy: 0.9703 - val_loss: 0.0243 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1292 - accuracy: 0.9809 - val_loss: 0.0254 - val_accuracy: 0.9958\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0976 - accuracy: 0.9831 - val_loss: 0.0272 - val_accuracy: 0.9958\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1518 - accuracy: 0.9746 - val_loss: 0.0254 - val_accuracy: 0.9979\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2492 - accuracy: 0.9640 - val_loss: 0.0270 - val_accuracy: 0.9958\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1306 - accuracy: 0.9831 - val_loss: 0.0291 - val_accuracy: 0.9936\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1723 - accuracy: 0.9640 - val_loss: 0.0253 - val_accuracy: 0.9958\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1352 - accuracy: 0.9725 - val_loss: 0.0412 - val_accuracy: 0.9831\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2160 - accuracy: 0.9576 - val_loss: 0.0339 - val_accuracy: 0.9894\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0714 - accuracy: 0.9725 - val_loss: 0.0324 - val_accuracy: 0.9915\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2115 - accuracy: 0.9640 - val_loss: 0.0387 - val_accuracy: 0.9852\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1408 - accuracy: 0.9746 - val_loss: 0.0242 - val_accuracy: 0.9979\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1671 - accuracy: 0.9640 - val_loss: 0.0410 - val_accuracy: 0.9894\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1219 - accuracy: 0.9682 - val_loss: 0.0283 - val_accuracy: 0.9936\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2134 - accuracy: 0.9597 - val_loss: 0.0276 - val_accuracy: 0.9958\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1768 - accuracy: 0.9619 - val_loss: 0.0301 - val_accuracy: 0.9915\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1597 - accuracy: 0.9661 - val_loss: 0.0256 - val_accuracy: 0.9936\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0959 - accuracy: 0.9788 - val_loss: 0.0441 - val_accuracy: 0.9809\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1503 - accuracy: 0.9682 - val_loss: 0.0223 - val_accuracy: 0.9958\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0909 - accuracy: 0.9682 - val_loss: 0.0407 - val_accuracy: 0.9873\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1444 - accuracy: 0.9597 - val_loss: 0.0262 - val_accuracy: 0.9936\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1326 - accuracy: 0.9725 - val_loss: 0.0292 - val_accuracy: 0.9936\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1672 - accuracy: 0.9703 - val_loss: 0.0287 - val_accuracy: 0.9915\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1620 - accuracy: 0.9725 - val_loss: 0.0251 - val_accuracy: 0.9936\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2159 - accuracy: 0.9576 - val_loss: 0.0247 - val_accuracy: 0.9958\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1093 - accuracy: 0.9725 - val_loss: 0.0205 - val_accuracy: 0.9979\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1661 - accuracy: 0.9555 - val_loss: 0.0268 - val_accuracy: 0.9936\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1351 - accuracy: 0.9809 - val_loss: 0.0205 - val_accuracy: 0.9979\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0850 - accuracy: 0.9809 - val_loss: 0.0218 - val_accuracy: 0.9979\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1536 - accuracy: 0.9682 - val_loss: 0.0253 - val_accuracy: 0.9936\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0888 - accuracy: 0.9767 - val_loss: 0.0284 - val_accuracy: 0.9936\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2252 - accuracy: 0.9534 - val_loss: 0.0384 - val_accuracy: 0.9831\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 0.0233 - val_accuracy: 0.9979\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1320 - accuracy: 0.9682 - val_loss: 0.0240 - val_accuracy: 0.9958\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0948 - accuracy: 0.9809 - val_loss: 0.0189 - val_accuracy: 0.9979\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.0703 - accuracy: 0.9767 - val_loss: 0.0183 - val_accuracy: 0.9979\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2572 - accuracy: 0.9682 - val_loss: 0.0234 - val_accuracy: 0.9958\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1055 - accuracy: 0.9788 - val_loss: 0.0189 - val_accuracy: 0.9979\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0571 - accuracy: 0.9703 - val_loss: 0.0281 - val_accuracy: 0.9936\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1642 - accuracy: 0.9703 - val_loss: 0.0363 - val_accuracy: 0.9915\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1077 - accuracy: 0.9597 - val_loss: 0.0316 - val_accuracy: 0.9915\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1691 - accuracy: 0.9725 - val_loss: 0.0211 - val_accuracy: 0.9979\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1388 - accuracy: 0.9682 - val_loss: 0.0219 - val_accuracy: 0.9979\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1989 - accuracy: 0.9682 - val_loss: 0.0314 - val_accuracy: 0.9958\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1468 - accuracy: 0.9788 - val_loss: 0.0250 - val_accuracy: 0.9958\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0666 - accuracy: 0.9809 - val_loss: 0.0218 - val_accuracy: 0.9979\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0565 - accuracy: 0.9831 - val_loss: 0.0221 - val_accuracy: 0.9979\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1657 - accuracy: 0.9661 - val_loss: 0.0261 - val_accuracy: 0.9936\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0505 - accuracy: 0.9788 - val_loss: 0.0216 - val_accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "\n",
    "# Fit with early stopping and model checkpoint to save the best models. \n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# # patient early stopping\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "# mc = ModelCheckpoint('models/model-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "# # evaluate the model\n",
    "# history = model.fit(X_train, y_train ,verbose=1, epochs=500, batch_size=64,\n",
    "#                     validation_data=(X_test, y_test), callbacks=[es, mc])\n",
    "\n",
    "#Fit with no early stopping or other callbacks\n",
    "history = model.fit(X_train, Y_val,verbose=1, epochs=500, batch_size=128,\n",
    "                    validation_data=(X_test, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0216 - accuracy: 0.9958\n",
      "Accuracy =  99.57627058029175 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "_, acc = model.evaluate(X_train, Y_val)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://5d5995a4-a7ad-4e9f-9194-e2c381f2cc79/assets\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.externals import joblib\n",
    "import pickle\n",
    "filename = 'Valfinalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction_test = model.predict(X_test)    \n",
    "# print(y_test, prediction_test)\n",
    "# print(\"Mean sq. errror between y_test and predicted =\", np.mean(prediction_test-y_test)**2)\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-entropy loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training  Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "##model predictions\n",
    "###model already knows there are two outputs from the definition\n",
    "# predictions = model.predict(X_test)\n",
    "y_pred_val= model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 1.00000000e+00, 1.00000000e+00,\n",
       "       1.00000000e+00, 1.00000000e+00, 3.47792489e-10, 1.66182995e-01,\n",
       "       4.87575568e-02, 1.51227638e-01, 7.53038785e-06, 1.17583789e-01,\n",
       "       6.99619432e-06, 4.88514663e-04, 4.27259874e-06, 2.58865673e-02,\n",
       "       1.23998313e-03, 7.41464464e-06, 9.78786312e-03, 1.58782993e-02,\n",
       "       4.45069466e-03, 5.30489313e-04, 1.17936768e-02, 7.42029445e-03,\n",
       "       4.40610638e-05, 1.30858261e-03, 3.82495746e-02, 4.84645142e-08,\n",
       "       5.24518006e-02, 3.34261298e-01, 1.97610735e-16, 2.18888404e-19,\n",
       "       4.43633758e-02, 9.10104079e-16, 3.87153818e-07, 2.59269714e-01,\n",
       "       6.39276016e-25, 9.09457635e-03, 4.24365027e-07, 5.16841392e-05,\n",
       "       2.98561325e-04, 3.78953777e-02, 1.03261961e-07, 1.48019956e-06,\n",
       "       6.00786781e-11, 8.92459648e-05, 8.80024105e-04, 5.30166508e-05,\n",
       "       3.02002323e-03, 2.85068341e-02, 1.31658968e-02, 1.52448779e-02,\n",
       "       4.71364073e-02, 1.07860388e-02, 2.04661803e-04, 9.07058653e-04,\n",
       "       3.74810338e-01, 2.35864103e-01, 1.84280361e-05, 6.06477785e-11,\n",
       "       1.62160092e-07, 1.83069073e-02, 1.80555403e-01, 7.64056040e-06,\n",
       "       1.13255419e-02, 1.35927301e-04, 1.15988230e-24, 9.82437814e-06,\n",
       "       8.30673486e-09, 1.06374949e-01, 6.39255100e-04, 1.98026132e-02,\n",
       "       2.05111587e-11, 1.57811090e-01, 2.57902814e-11, 2.41030231e-02,\n",
       "       4.62253615e-02, 1.91530457e-03, 5.43809354e-01, 1.36036664e-01,\n",
       "       2.10831974e-08, 5.33824004e-02, 1.88023057e-02, 1.28453309e-14,\n",
       "       1.40461326e-01, 1.44743487e-01, 6.56337570e-03, 5.26884757e-02,\n",
       "       1.23973924e-03, 6.64023957e-12, 3.40262130e-02, 1.27028812e-07,\n",
       "       8.92583557e-06, 2.13585328e-03, 1.00001417e-01, 6.09453250e-15,\n",
       "       2.65289038e-01, 1.04794102e-02, 2.94018211e-03, 2.68758682e-04,\n",
       "       6.28756313e-03, 2.08814192e-04, 7.99021880e-27, 6.41528219e-02,\n",
       "       1.26572791e-04, 2.88489312e-02, 1.69235423e-01, 1.89464487e-07,\n",
       "       5.28714597e-01, 1.01588815e-01, 4.46060963e-04, 9.27717610e-06,\n",
       "       2.81787273e-02, 1.23794876e-01, 8.91746581e-02, 1.21067204e-02,\n",
       "       1.52480498e-01, 7.98639366e-12, 1.79765448e-01, 1.65371592e-08,\n",
       "       1.09190568e-02, 3.67214270e-05, 1.09814756e-01, 7.96781421e-07,\n",
       "       9.98275459e-01, 9.99996364e-01, 1.00000000e+00, 9.99633551e-01,\n",
       "       9.99474227e-01, 9.96420681e-01, 9.99972641e-01, 6.51982486e-01,\n",
       "       9.95095968e-01, 9.73465145e-01, 9.99041677e-01, 9.99998868e-01,\n",
       "       9.99966085e-01, 9.95144486e-01, 9.99997318e-01, 9.67263579e-01,\n",
       "       9.11816120e-01, 9.98160958e-01, 9.98983562e-01, 9.99999881e-01,\n",
       "       9.35674489e-01, 9.08649445e-01, 1.00000000e+00, 9.38769221e-01,\n",
       "       9.99999881e-01, 7.98199475e-01, 9.99997854e-01, 9.98827636e-01,\n",
       "       9.99637425e-01, 1.00000000e+00, 9.99999702e-01, 9.99999821e-01,\n",
       "       9.81445372e-01, 9.51850951e-01, 9.85494018e-01, 9.99994516e-01,\n",
       "       1.00000000e+00, 1.00000000e+00, 8.13422143e-01, 9.88661289e-01,\n",
       "       9.96874094e-01, 9.99981940e-01, 9.99988854e-01, 9.99727249e-01,\n",
       "       9.99998569e-01, 9.93620992e-01, 9.99994755e-01, 9.88528430e-01,\n",
       "       9.88079429e-01, 7.69093573e-01, 9.99999821e-01, 8.04850698e-01,\n",
       "       9.95665133e-01, 8.47167194e-01, 9.88369346e-01, 1.00000000e+00,\n",
       "       9.61925805e-01, 9.94283319e-01, 9.99985635e-01, 9.69157398e-01,\n",
       "       9.97782767e-01, 9.99993980e-01, 9.97324705e-01, 9.74990785e-01,\n",
       "       9.67135608e-01, 9.97858226e-01, 9.34298396e-01, 9.99065578e-01,\n",
       "       9.99709547e-01, 9.97399092e-01, 9.56335962e-01, 9.98764396e-01,\n",
       "       9.92314517e-01, 1.00000000e+00, 9.72609282e-01, 1.00000000e+00,\n",
       "       9.99996722e-01, 9.71174002e-01, 9.99991596e-01, 9.99491513e-01,\n",
       "       9.99994457e-01, 9.98899162e-01, 9.45274532e-01, 9.99316931e-01,\n",
       "       9.20930922e-01, 1.00000000e+00, 9.99999106e-01, 9.99646842e-01,\n",
       "       9.99565065e-01, 1.00000000e+00, 9.91621017e-01, 9.99999404e-01,\n",
       "       9.96505797e-01, 1.00000000e+00, 9.99953806e-01, 1.00000000e+00,\n",
       "       9.99995291e-01, 9.68840361e-01, 9.98712361e-01, 1.00000000e+00,\n",
       "       1.00000000e+00, 9.99998808e-01, 9.99542952e-01, 9.82530951e-01,\n",
       "       8.62495899e-01, 8.98414195e-01, 9.30558324e-01, 1.00000000e+00,\n",
       "       9.38606143e-01, 9.99618173e-01, 9.99185383e-01, 9.99999762e-01,\n",
       "       9.48554099e-01, 9.82237518e-01, 9.76960659e-01, 9.99999702e-01,\n",
       "       9.52112436e-01, 6.98201120e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 2.64465267e-34, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.72143412e-36, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.27419902e-30,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = y_pred_val.reshape([472,]) ##Reshape needed for deriving table of actual vs predicted values\n",
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = (y_pred_val > 0)#needed for deriving confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[234,   0],\n",
       "       [  2, 236]], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Memory test for Valence\n",
    "cm = confusion_matrix(y_pred_val, Y_val)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv=np.arange(2,3)\n",
    "\n",
    "dataframe=pd.DataFrame(cm)\n",
    "\n",
    "# Create heatmap\n",
    "\n",
    "sns.heatmap(dataframe, annot=True, cbar=None, cmap='Blues')\n",
    "\n",
    "plt.title('Confusion Matrix'), plt.tight_layout()\n",
    "\n",
    "plt.ylabel('Actual class'), plt.xlabel('Predicted Class')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       236\n",
      "           1       0.99      1.00      1.00       236\n",
      "\n",
      "    accuracy                           1.00       472\n",
      "   macro avg       1.00      1.00      1.00       472\n",
      "weighted avg       1.00      1.00      1.00       472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report( Y_val,y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm/np.sum(cm), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472,)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0         1       True\n",
       "1         1       True\n",
       "2         1       True\n",
       "3         1       True\n",
       "4         1       True\n",
       "..      ...        ...\n",
       "467       0      False\n",
       "468       0      False\n",
       "469       0      False\n",
       "470       0      False\n",
       "471       0      False\n",
       "\n",
       "[472 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Actual': Y_val, 'Predicted': y_pred_val})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 16)                1168      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1)                 0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,187\n",
      "Trainable params: 1,187\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Too simple??\n",
    "\n",
    "model_aro = Sequential()\n",
    "model_aro.add(Dense(16, input_dim=72, activation='relu')) \n",
    "model_aro.add(Dropout(0.02))\n",
    "model_aro.add(Dense(1)) \n",
    "model_aro.add(Dropout(0.02))\n",
    "model_aro.add(Dense(1)) \n",
    "model_aro.add(Activation('sigmoid'))  \n",
    "model_aro.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',             #also try adam\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "print(model_aro.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "4/4 [==============================] - 1s 72ms/step - loss: 14.9164 - accuracy: 0.6801 - val_loss: 10.2212 - val_accuracy: 0.7161\n",
      "Epoch 2/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 10.5416 - accuracy: 0.7246 - val_loss: 9.0772 - val_accuracy: 0.7288\n",
      "Epoch 3/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 10.2799 - accuracy: 0.7352 - val_loss: 7.7991 - val_accuracy: 0.7500\n",
      "Epoch 4/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 8.5019 - accuracy: 0.7521 - val_loss: 7.0129 - val_accuracy: 0.7775\n",
      "Epoch 5/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 8.8599 - accuracy: 0.7648 - val_loss: 6.2506 - val_accuracy: 0.7860\n",
      "Epoch 6/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 7.4220 - accuracy: 0.7924 - val_loss: 5.6531 - val_accuracy: 0.7881\n",
      "Epoch 7/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 8.0418 - accuracy: 0.7542 - val_loss: 5.1284 - val_accuracy: 0.7881\n",
      "Epoch 8/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 7.0391 - accuracy: 0.7797 - val_loss: 4.6425 - val_accuracy: 0.7924\n",
      "Epoch 9/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 5.2869 - accuracy: 0.7903 - val_loss: 4.2410 - val_accuracy: 0.7966\n",
      "Epoch 10/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 4.7336 - accuracy: 0.7924 - val_loss: 3.9150 - val_accuracy: 0.8030\n",
      "Epoch 11/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 6.1802 - accuracy: 0.7924 - val_loss: 3.5883 - val_accuracy: 0.8114\n",
      "Epoch 12/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 4.5302 - accuracy: 0.7966 - val_loss: 3.3446 - val_accuracy: 0.8093\n",
      "Epoch 13/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 5.1525 - accuracy: 0.7669 - val_loss: 3.3480 - val_accuracy: 0.7924\n",
      "Epoch 14/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.4033 - accuracy: 0.7839 - val_loss: 2.9143 - val_accuracy: 0.8157\n",
      "Epoch 15/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.6388 - accuracy: 0.8220 - val_loss: 3.2298 - val_accuracy: 0.8072\n",
      "Epoch 16/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.9665 - accuracy: 0.7924 - val_loss: 2.7234 - val_accuracy: 0.8072\n",
      "Epoch 17/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.7131 - accuracy: 0.7860 - val_loss: 2.5307 - val_accuracy: 0.8114\n",
      "Epoch 18/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.4763 - accuracy: 0.7924 - val_loss: 2.5284 - val_accuracy: 0.8220\n",
      "Epoch 19/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.8681 - accuracy: 0.7860 - val_loss: 2.3449 - val_accuracy: 0.8157\n",
      "Epoch 20/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.5789 - accuracy: 0.7903 - val_loss: 2.2016 - val_accuracy: 0.8242\n",
      "Epoch 21/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 3.5911 - accuracy: 0.8178 - val_loss: 2.1232 - val_accuracy: 0.8284\n",
      "Epoch 22/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 4.0491 - accuracy: 0.8051 - val_loss: 2.0412 - val_accuracy: 0.8326\n",
      "Epoch 23/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 3.1083 - accuracy: 0.8242 - val_loss: 1.9365 - val_accuracy: 0.8411\n",
      "Epoch 24/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 3.2499 - accuracy: 0.8220 - val_loss: 1.8624 - val_accuracy: 0.8390\n",
      "Epoch 25/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.9634 - accuracy: 0.8305 - val_loss: 1.7705 - val_accuracy: 0.8411\n",
      "Epoch 26/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 4.0262 - accuracy: 0.8030 - val_loss: 1.7300 - val_accuracy: 0.8326\n",
      "Epoch 27/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 3.3761 - accuracy: 0.8136 - val_loss: 1.6395 - val_accuracy: 0.8390\n",
      "Epoch 28/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.4492 - accuracy: 0.8178 - val_loss: 1.5844 - val_accuracy: 0.8390\n",
      "Epoch 29/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2.9168 - accuracy: 0.8093 - val_loss: 1.6005 - val_accuracy: 0.8411\n",
      "Epoch 30/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 3.8146 - accuracy: 0.7903 - val_loss: 1.5983 - val_accuracy: 0.8136\n",
      "Epoch 31/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.5810 - accuracy: 0.8199 - val_loss: 1.4923 - val_accuracy: 0.8432\n",
      "Epoch 32/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 3.1761 - accuracy: 0.8178 - val_loss: 1.3891 - val_accuracy: 0.8369\n",
      "Epoch 33/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.5851 - accuracy: 0.8157 - val_loss: 1.3771 - val_accuracy: 0.8242\n",
      "Epoch 34/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4439 - accuracy: 0.8284 - val_loss: 1.3156 - val_accuracy: 0.8411\n",
      "Epoch 35/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.4060 - accuracy: 0.8157 - val_loss: 1.2722 - val_accuracy: 0.8347\n",
      "Epoch 36/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.8531 - accuracy: 0.8263 - val_loss: 1.2366 - val_accuracy: 0.8475\n",
      "Epoch 37/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 2.0956 - accuracy: 0.8390 - val_loss: 1.2087 - val_accuracy: 0.8496\n",
      "Epoch 38/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 2.9715 - accuracy: 0.8093 - val_loss: 1.1830 - val_accuracy: 0.8347\n",
      "Epoch 39/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2.5475 - accuracy: 0.8072 - val_loss: 1.1329 - val_accuracy: 0.8453\n",
      "Epoch 40/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 1.9197 - accuracy: 0.8326 - val_loss: 1.1053 - val_accuracy: 0.8453\n",
      "Epoch 41/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.8275 - accuracy: 0.8220 - val_loss: 1.0726 - val_accuracy: 0.8411\n",
      "Epoch 42/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.8333 - accuracy: 0.8157 - val_loss: 1.1199 - val_accuracy: 0.8305\n",
      "Epoch 43/500\n",
      "4/4 [==============================] - 0s 39ms/step - loss: 2.3037 - accuracy: 0.8326 - val_loss: 1.0672 - val_accuracy: 0.8581\n",
      "Epoch 44/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 2.0756 - accuracy: 0.8157 - val_loss: 1.0779 - val_accuracy: 0.8305\n",
      "Epoch 45/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.9512 - accuracy: 0.8030 - val_loss: 1.0632 - val_accuracy: 0.8496\n",
      "Epoch 46/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 2.0682 - accuracy: 0.8008 - val_loss: 0.9710 - val_accuracy: 0.8432\n",
      "Epoch 47/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.8859 - accuracy: 0.8263 - val_loss: 0.9347 - val_accuracy: 0.8581\n",
      "Epoch 48/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.8950 - accuracy: 0.8369 - val_loss: 0.9205 - val_accuracy: 0.8559\n",
      "Epoch 49/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 2.2256 - accuracy: 0.8242 - val_loss: 0.8909 - val_accuracy: 0.8581\n",
      "Epoch 50/500\n",
      "4/4 [==============================] - 0s 28ms/step - loss: 1.5170 - accuracy: 0.8305 - val_loss: 0.8716 - val_accuracy: 0.8538\n",
      "Epoch 51/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.7605 - accuracy: 0.8263 - val_loss: 0.8570 - val_accuracy: 0.8538\n",
      "Epoch 52/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 1.8003 - accuracy: 0.8157 - val_loss: 0.8852 - val_accuracy: 0.8517\n",
      "Epoch 53/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.6768 - accuracy: 0.8220 - val_loss: 0.8697 - val_accuracy: 0.8411\n",
      "Epoch 54/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.6932 - accuracy: 0.8326 - val_loss: 0.8263 - val_accuracy: 0.8602\n",
      "Epoch 55/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3145 - accuracy: 0.8347 - val_loss: 0.7905 - val_accuracy: 0.8581\n",
      "Epoch 56/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 2.3048 - accuracy: 0.8242 - val_loss: 0.7726 - val_accuracy: 0.8644\n",
      "Epoch 57/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 1.3203 - accuracy: 0.8305 - val_loss: 0.7581 - val_accuracy: 0.8623\n",
      "Epoch 58/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.3360 - accuracy: 0.8432 - val_loss: 0.7571 - val_accuracy: 0.8644\n",
      "Epoch 59/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 1.8703 - accuracy: 0.8369 - val_loss: 0.7396 - val_accuracy: 0.8665\n",
      "Epoch 60/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.8860 - accuracy: 0.8242 - val_loss: 0.7338 - val_accuracy: 0.8686\n",
      "Epoch 61/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1578 - accuracy: 0.8517 - val_loss: 0.7233 - val_accuracy: 0.8644\n",
      "Epoch 62/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.5415 - accuracy: 0.8538 - val_loss: 0.7127 - val_accuracy: 0.8623\n",
      "Epoch 63/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.3219 - accuracy: 0.8369 - val_loss: 0.7029 - val_accuracy: 0.8665\n",
      "Epoch 64/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2903 - accuracy: 0.8453 - val_loss: 0.6799 - val_accuracy: 0.8665\n",
      "Epoch 65/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4999 - accuracy: 0.8432 - val_loss: 0.7187 - val_accuracy: 0.8496\n",
      "Epoch 66/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.4599 - accuracy: 0.8475 - val_loss: 0.8021 - val_accuracy: 0.8559\n",
      "Epoch 67/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.5114 - accuracy: 0.8157 - val_loss: 0.7543 - val_accuracy: 0.8475\n",
      "Epoch 68/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.6296 - accuracy: 0.8263 - val_loss: 0.6533 - val_accuracy: 0.8644\n",
      "Epoch 69/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.6170 - accuracy: 0.8305 - val_loss: 0.6495 - val_accuracy: 0.8602\n",
      "Epoch 70/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1081 - accuracy: 0.8496 - val_loss: 0.6401 - val_accuracy: 0.8729\n",
      "Epoch 71/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 1.4343 - accuracy: 0.8496 - val_loss: 0.6156 - val_accuracy: 0.8771\n",
      "Epoch 72/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.8456 - accuracy: 0.8475 - val_loss: 0.6016 - val_accuracy: 0.8708\n",
      "Epoch 73/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8324 - accuracy: 0.8602 - val_loss: 0.5897 - val_accuracy: 0.8729\n",
      "Epoch 74/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.9523 - accuracy: 0.8602 - val_loss: 0.5779 - val_accuracy: 0.8686\n",
      "Epoch 75/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.1867 - accuracy: 0.8411 - val_loss: 0.5858 - val_accuracy: 0.8729\n",
      "Epoch 76/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.2573 - accuracy: 0.8369 - val_loss: 0.5937 - val_accuracy: 0.8686\n",
      "Epoch 77/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.6787 - accuracy: 0.8347 - val_loss: 0.5736 - val_accuracy: 0.8708\n",
      "Epoch 78/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 1.2352 - accuracy: 0.8369 - val_loss: 0.5704 - val_accuracy: 0.8686\n",
      "Epoch 79/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 1.4561 - accuracy: 0.8369 - val_loss: 0.5775 - val_accuracy: 0.8686\n",
      "Epoch 80/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.3262 - accuracy: 0.8538 - val_loss: 0.5317 - val_accuracy: 0.8665\n",
      "Epoch 81/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1240 - accuracy: 0.8305 - val_loss: 0.5407 - val_accuracy: 0.8686\n",
      "Epoch 82/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 1.3926 - accuracy: 0.8326 - val_loss: 0.5504 - val_accuracy: 0.8771\n",
      "Epoch 83/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.4317 - accuracy: 0.8432 - val_loss: 0.5224 - val_accuracy: 0.8729\n",
      "Epoch 84/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9789 - accuracy: 0.8453 - val_loss: 0.4927 - val_accuracy: 0.8750\n",
      "Epoch 85/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.1837 - accuracy: 0.8623 - val_loss: 0.4847 - val_accuracy: 0.8729\n",
      "Epoch 86/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 1.1395 - accuracy: 0.8199 - val_loss: 0.4657 - val_accuracy: 0.8792\n",
      "Epoch 87/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.2124 - accuracy: 0.8581 - val_loss: 0.4928 - val_accuracy: 0.8877\n",
      "Epoch 88/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.9686 - accuracy: 0.8559 - val_loss: 0.4773 - val_accuracy: 0.8708\n",
      "Epoch 89/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.9015 - accuracy: 0.8581 - val_loss: 0.4541 - val_accuracy: 0.8708\n",
      "Epoch 90/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 1.1233 - accuracy: 0.8390 - val_loss: 0.4260 - val_accuracy: 0.8792\n",
      "Epoch 91/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0999 - accuracy: 0.8369 - val_loss: 0.4139 - val_accuracy: 0.8814\n",
      "Epoch 92/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8387 - accuracy: 0.8517 - val_loss: 0.4098 - val_accuracy: 0.8835\n",
      "Epoch 93/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.9376 - accuracy: 0.8581 - val_loss: 0.3974 - val_accuracy: 0.8877\n",
      "Epoch 94/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.7358 - accuracy: 0.8708 - val_loss: 0.3970 - val_accuracy: 0.8835\n",
      "Epoch 95/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8126 - accuracy: 0.8538 - val_loss: 0.4529 - val_accuracy: 0.8750\n",
      "Epoch 96/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8141 - accuracy: 0.8729 - val_loss: 0.4376 - val_accuracy: 0.8835\n",
      "Epoch 97/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.8374 - accuracy: 0.8771 - val_loss: 0.4840 - val_accuracy: 0.8792\n",
      "Epoch 98/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.9062 - accuracy: 0.8538 - val_loss: 0.3757 - val_accuracy: 0.8983\n",
      "Epoch 99/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.8359 - accuracy: 0.8686 - val_loss: 0.3703 - val_accuracy: 0.8962\n",
      "Epoch 100/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7519 - accuracy: 0.8665 - val_loss: 0.3550 - val_accuracy: 0.9089\n",
      "Epoch 101/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 1.0152 - accuracy: 0.8792 - val_loss: 0.3638 - val_accuracy: 0.8919\n",
      "Epoch 102/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.9358 - accuracy: 0.8538 - val_loss: 0.3395 - val_accuracy: 0.9025\n",
      "Epoch 103/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.7926 - accuracy: 0.8792 - val_loss: 0.3340 - val_accuracy: 0.9047\n",
      "Epoch 104/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6222 - accuracy: 0.8877 - val_loss: 0.3226 - val_accuracy: 0.9089\n",
      "Epoch 105/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.6379 - accuracy: 0.8771 - val_loss: 0.3253 - val_accuracy: 0.9068\n",
      "Epoch 106/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.7431 - accuracy: 0.8517 - val_loss: 0.3155 - val_accuracy: 0.8983\n",
      "Epoch 107/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.8995 - accuracy: 0.8559 - val_loss: 0.3285 - val_accuracy: 0.9089\n",
      "Epoch 108/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9691 - accuracy: 0.8665 - val_loss: 0.3159 - val_accuracy: 0.9025\n",
      "Epoch 109/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4796 - accuracy: 0.8792 - val_loss: 0.3144 - val_accuracy: 0.9004\n",
      "Epoch 110/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9831 - accuracy: 0.8581 - val_loss: 0.3166 - val_accuracy: 0.9110\n",
      "Epoch 111/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 1.2366 - accuracy: 0.8538 - val_loss: 0.3121 - val_accuracy: 0.9068\n",
      "Epoch 112/500\n",
      "4/4 [==============================] - 0s 31ms/step - loss: 0.5030 - accuracy: 0.8877 - val_loss: 0.3446 - val_accuracy: 0.9047\n",
      "Epoch 113/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.8220 - accuracy: 0.8771 - val_loss: 0.3423 - val_accuracy: 0.9004\n",
      "Epoch 114/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6855 - accuracy: 0.8814 - val_loss: 0.3431 - val_accuracy: 0.9004\n",
      "Epoch 115/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7773 - accuracy: 0.8771 - val_loss: 0.3104 - val_accuracy: 0.9089\n",
      "Epoch 116/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.7147 - accuracy: 0.8898 - val_loss: 0.2940 - val_accuracy: 0.9025\n",
      "Epoch 117/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.7891 - accuracy: 0.8750 - val_loss: 0.2837 - val_accuracy: 0.9047\n",
      "Epoch 118/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.9116 - accuracy: 0.8708 - val_loss: 0.3158 - val_accuracy: 0.9004\n",
      "Epoch 119/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.7734 - accuracy: 0.8835 - val_loss: 0.2716 - val_accuracy: 0.9068\n",
      "Epoch 120/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3754 - accuracy: 0.8898 - val_loss: 0.2750 - val_accuracy: 0.9131\n",
      "Epoch 121/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6085 - accuracy: 0.8771 - val_loss: 0.2762 - val_accuracy: 0.9174\n",
      "Epoch 122/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6993 - accuracy: 0.8835 - val_loss: 0.2619 - val_accuracy: 0.9110\n",
      "Epoch 123/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5941 - accuracy: 0.8686 - val_loss: 0.2599 - val_accuracy: 0.9153\n",
      "Epoch 124/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.6918 - accuracy: 0.8750 - val_loss: 0.3045 - val_accuracy: 0.9068\n",
      "Epoch 125/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5583 - accuracy: 0.8771 - val_loss: 0.2689 - val_accuracy: 0.9153\n",
      "Epoch 126/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.6661 - accuracy: 0.8750 - val_loss: 0.2662 - val_accuracy: 0.9216\n",
      "Epoch 127/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.7764 - accuracy: 0.8898 - val_loss: 0.2591 - val_accuracy: 0.9237\n",
      "Epoch 128/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4576 - accuracy: 0.8962 - val_loss: 0.2673 - val_accuracy: 0.9280\n",
      "Epoch 129/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5848 - accuracy: 0.8941 - val_loss: 0.3030 - val_accuracy: 0.9025\n",
      "Epoch 130/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5055 - accuracy: 0.8835 - val_loss: 0.2962 - val_accuracy: 0.9131\n",
      "Epoch 131/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6531 - accuracy: 0.8835 - val_loss: 0.2473 - val_accuracy: 0.9216\n",
      "Epoch 132/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5666 - accuracy: 0.9025 - val_loss: 0.2522 - val_accuracy: 0.9237\n",
      "Epoch 133/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.4726 - accuracy: 0.8983 - val_loss: 0.2588 - val_accuracy: 0.9195\n",
      "Epoch 134/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.7499 - accuracy: 0.8941 - val_loss: 0.2568 - val_accuracy: 0.9153\n",
      "Epoch 135/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.4819 - accuracy: 0.9110 - val_loss: 0.2585 - val_accuracy: 0.9237\n",
      "Epoch 136/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.6508 - accuracy: 0.8835 - val_loss: 0.2268 - val_accuracy: 0.9322\n",
      "Epoch 137/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.8340 - accuracy: 0.8750 - val_loss: 0.2361 - val_accuracy: 0.9280\n",
      "Epoch 138/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.6067 - accuracy: 0.9025 - val_loss: 0.2473 - val_accuracy: 0.9280\n",
      "Epoch 139/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5337 - accuracy: 0.8877 - val_loss: 0.2284 - val_accuracy: 0.9280\n",
      "Epoch 140/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4916 - accuracy: 0.9089 - val_loss: 0.2328 - val_accuracy: 0.9301\n",
      "Epoch 141/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5953 - accuracy: 0.9110 - val_loss: 0.2261 - val_accuracy: 0.9280\n",
      "Epoch 142/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5411 - accuracy: 0.9089 - val_loss: 0.2201 - val_accuracy: 0.9280\n",
      "Epoch 143/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4725 - accuracy: 0.8919 - val_loss: 0.2184 - val_accuracy: 0.9364\n",
      "Epoch 144/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5418 - accuracy: 0.8835 - val_loss: 0.2180 - val_accuracy: 0.9301\n",
      "Epoch 145/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.5618 - accuracy: 0.8856 - val_loss: 0.2170 - val_accuracy: 0.9280\n",
      "Epoch 146/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4809 - accuracy: 0.9004 - val_loss: 0.2350 - val_accuracy: 0.9258\n",
      "Epoch 147/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4085 - accuracy: 0.9174 - val_loss: 0.2056 - val_accuracy: 0.9322\n",
      "Epoch 148/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4575 - accuracy: 0.8792 - val_loss: 0.2073 - val_accuracy: 0.9237\n",
      "Epoch 149/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3895 - accuracy: 0.8983 - val_loss: 0.2084 - val_accuracy: 0.9280\n",
      "Epoch 150/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3919 - accuracy: 0.9195 - val_loss: 0.2016 - val_accuracy: 0.9322\n",
      "Epoch 151/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5210 - accuracy: 0.9025 - val_loss: 0.2116 - val_accuracy: 0.9322\n",
      "Epoch 152/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3404 - accuracy: 0.9153 - val_loss: 0.2045 - val_accuracy: 0.9322\n",
      "Epoch 153/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3790 - accuracy: 0.8898 - val_loss: 0.1950 - val_accuracy: 0.9301\n",
      "Epoch 154/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3796 - accuracy: 0.9047 - val_loss: 0.1857 - val_accuracy: 0.9407\n",
      "Epoch 155/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.4833 - accuracy: 0.8856 - val_loss: 0.1846 - val_accuracy: 0.9407\n",
      "Epoch 156/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.4662 - accuracy: 0.9089 - val_loss: 0.1898 - val_accuracy: 0.9386\n",
      "Epoch 157/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5770 - accuracy: 0.8729 - val_loss: 0.1853 - val_accuracy: 0.9428\n",
      "Epoch 158/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5255 - accuracy: 0.9089 - val_loss: 0.2527 - val_accuracy: 0.9131\n",
      "Epoch 159/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3835 - accuracy: 0.9025 - val_loss: 0.2829 - val_accuracy: 0.8983\n",
      "Epoch 160/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.5695 - accuracy: 0.8941 - val_loss: 0.2210 - val_accuracy: 0.9258\n",
      "Epoch 161/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.5760 - accuracy: 0.8983 - val_loss: 0.1828 - val_accuracy: 0.9386\n",
      "Epoch 162/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3911 - accuracy: 0.9025 - val_loss: 0.2163 - val_accuracy: 0.9258\n",
      "Epoch 163/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3757 - accuracy: 0.8941 - val_loss: 0.2657 - val_accuracy: 0.9110\n",
      "Epoch 164/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3829 - accuracy: 0.8919 - val_loss: 0.2093 - val_accuracy: 0.9322\n",
      "Epoch 165/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3715 - accuracy: 0.9110 - val_loss: 0.1761 - val_accuracy: 0.9322\n",
      "Epoch 166/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4793 - accuracy: 0.8962 - val_loss: 0.1664 - val_accuracy: 0.9449\n",
      "Epoch 167/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3456 - accuracy: 0.9195 - val_loss: 0.1709 - val_accuracy: 0.9492\n",
      "Epoch 168/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3172 - accuracy: 0.9301 - val_loss: 0.1706 - val_accuracy: 0.9428\n",
      "Epoch 169/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.5170 - accuracy: 0.8898 - val_loss: 0.1602 - val_accuracy: 0.9364\n",
      "Epoch 170/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4996 - accuracy: 0.9131 - val_loss: 0.1612 - val_accuracy: 0.9386\n",
      "Epoch 171/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.4955 - accuracy: 0.9004 - val_loss: 0.1799 - val_accuracy: 0.9301\n",
      "Epoch 172/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.5835 - accuracy: 0.9004 - val_loss: 0.1596 - val_accuracy: 0.9449\n",
      "Epoch 173/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2599 - accuracy: 0.9343 - val_loss: 0.1573 - val_accuracy: 0.9513\n",
      "Epoch 174/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4675 - accuracy: 0.9258 - val_loss: 0.1629 - val_accuracy: 0.9386\n",
      "Epoch 175/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3165 - accuracy: 0.9216 - val_loss: 0.1565 - val_accuracy: 0.9470\n",
      "Epoch 176/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.5578 - accuracy: 0.9110 - val_loss: 0.1536 - val_accuracy: 0.9428\n",
      "Epoch 177/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3575 - accuracy: 0.9068 - val_loss: 0.1508 - val_accuracy: 0.9407\n",
      "Epoch 178/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2629 - accuracy: 0.9237 - val_loss: 0.1526 - val_accuracy: 0.9492\n",
      "Epoch 179/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3786 - accuracy: 0.9237 - val_loss: 0.1470 - val_accuracy: 0.9470\n",
      "Epoch 180/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3199 - accuracy: 0.9195 - val_loss: 0.1463 - val_accuracy: 0.9470\n",
      "Epoch 181/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3125 - accuracy: 0.9047 - val_loss: 0.1451 - val_accuracy: 0.9449\n",
      "Epoch 182/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3778 - accuracy: 0.9216 - val_loss: 0.1618 - val_accuracy: 0.9428\n",
      "Epoch 183/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3127 - accuracy: 0.9195 - val_loss: 0.1526 - val_accuracy: 0.9428\n",
      "Epoch 184/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2376 - accuracy: 0.9068 - val_loss: 0.1420 - val_accuracy: 0.9449\n",
      "Epoch 185/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2981 - accuracy: 0.9216 - val_loss: 0.1534 - val_accuracy: 0.9470\n",
      "Epoch 186/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3789 - accuracy: 0.9047 - val_loss: 0.1507 - val_accuracy: 0.9386\n",
      "Epoch 187/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3197 - accuracy: 0.9131 - val_loss: 0.1390 - val_accuracy: 0.9470\n",
      "Epoch 188/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3115 - accuracy: 0.9258 - val_loss: 0.1365 - val_accuracy: 0.9449\n",
      "Epoch 189/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2621 - accuracy: 0.9153 - val_loss: 0.1362 - val_accuracy: 0.9513\n",
      "Epoch 190/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3502 - accuracy: 0.9153 - val_loss: 0.1364 - val_accuracy: 0.9428\n",
      "Epoch 191/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3812 - accuracy: 0.9174 - val_loss: 0.1313 - val_accuracy: 0.9555\n",
      "Epoch 192/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3120 - accuracy: 0.9258 - val_loss: 0.1297 - val_accuracy: 0.9470\n",
      "Epoch 193/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3483 - accuracy: 0.9131 - val_loss: 0.1341 - val_accuracy: 0.9470\n",
      "Epoch 194/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4408 - accuracy: 0.8941 - val_loss: 0.1498 - val_accuracy: 0.9343\n",
      "Epoch 195/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3488 - accuracy: 0.9004 - val_loss: 0.1428 - val_accuracy: 0.9492\n",
      "Epoch 196/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4813 - accuracy: 0.8983 - val_loss: 0.1416 - val_accuracy: 0.9386\n",
      "Epoch 197/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.3129 - accuracy: 0.9068 - val_loss: 0.1412 - val_accuracy: 0.9513\n",
      "Epoch 198/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.4499 - accuracy: 0.9068 - val_loss: 0.1461 - val_accuracy: 0.9386\n",
      "Epoch 199/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3023 - accuracy: 0.9131 - val_loss: 0.1478 - val_accuracy: 0.9534\n",
      "Epoch 200/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3173 - accuracy: 0.9089 - val_loss: 0.1407 - val_accuracy: 0.9407\n",
      "Epoch 201/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.3143 - accuracy: 0.9258 - val_loss: 0.1344 - val_accuracy: 0.9470\n",
      "Epoch 202/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2261 - accuracy: 0.9322 - val_loss: 0.1291 - val_accuracy: 0.9555\n",
      "Epoch 203/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.4265 - accuracy: 0.9047 - val_loss: 0.1313 - val_accuracy: 0.9449\n",
      "Epoch 204/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.4216 - accuracy: 0.9237 - val_loss: 0.1379 - val_accuracy: 0.9534\n",
      "Epoch 205/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2569 - accuracy: 0.9280 - val_loss: 0.1218 - val_accuracy: 0.9555\n",
      "Epoch 206/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2713 - accuracy: 0.9195 - val_loss: 0.1225 - val_accuracy: 0.9470\n",
      "Epoch 207/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2594 - accuracy: 0.9195 - val_loss: 0.1224 - val_accuracy: 0.9576\n",
      "Epoch 208/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3245 - accuracy: 0.9258 - val_loss: 0.1476 - val_accuracy: 0.9386\n",
      "Epoch 209/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2954 - accuracy: 0.9216 - val_loss: 0.1203 - val_accuracy: 0.9555\n",
      "Epoch 210/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2502 - accuracy: 0.9343 - val_loss: 0.1188 - val_accuracy: 0.9576\n",
      "Epoch 211/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2191 - accuracy: 0.9280 - val_loss: 0.1110 - val_accuracy: 0.9576\n",
      "Epoch 212/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2495 - accuracy: 0.9258 - val_loss: 0.1106 - val_accuracy: 0.9513\n",
      "Epoch 213/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2933 - accuracy: 0.9195 - val_loss: 0.1081 - val_accuracy: 0.9619\n",
      "Epoch 214/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3834 - accuracy: 0.9047 - val_loss: 0.1119 - val_accuracy: 0.9428\n",
      "Epoch 215/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3115 - accuracy: 0.9110 - val_loss: 0.1036 - val_accuracy: 0.9597\n",
      "Epoch 216/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3640 - accuracy: 0.9280 - val_loss: 0.1019 - val_accuracy: 0.9619\n",
      "Epoch 217/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2932 - accuracy: 0.9343 - val_loss: 0.1077 - val_accuracy: 0.9576\n",
      "Epoch 218/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1454 - accuracy: 0.9364 - val_loss: 0.1060 - val_accuracy: 0.9661\n",
      "Epoch 219/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1908 - accuracy: 0.9343 - val_loss: 0.0977 - val_accuracy: 0.9661\n",
      "Epoch 220/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2771 - accuracy: 0.9322 - val_loss: 0.1058 - val_accuracy: 0.9449\n",
      "Epoch 221/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2564 - accuracy: 0.9195 - val_loss: 0.1066 - val_accuracy: 0.9576\n",
      "Epoch 222/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2823 - accuracy: 0.9407 - val_loss: 0.1054 - val_accuracy: 0.9576\n",
      "Epoch 223/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2811 - accuracy: 0.9195 - val_loss: 0.1014 - val_accuracy: 0.9492\n",
      "Epoch 224/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2216 - accuracy: 0.9322 - val_loss: 0.0945 - val_accuracy: 0.9619\n",
      "Epoch 225/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.3144 - accuracy: 0.9470 - val_loss: 0.0947 - val_accuracy: 0.9640\n",
      "Epoch 226/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2545 - accuracy: 0.9280 - val_loss: 0.0961 - val_accuracy: 0.9534\n",
      "Epoch 227/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2098 - accuracy: 0.9470 - val_loss: 0.0934 - val_accuracy: 0.9661\n",
      "Epoch 228/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2604 - accuracy: 0.9407 - val_loss: 0.0906 - val_accuracy: 0.9619\n",
      "Epoch 229/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2620 - accuracy: 0.9343 - val_loss: 0.0912 - val_accuracy: 0.9555\n",
      "Epoch 230/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1711 - accuracy: 0.9428 - val_loss: 0.0898 - val_accuracy: 0.9661\n",
      "Epoch 231/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2179 - accuracy: 0.9301 - val_loss: 0.0905 - val_accuracy: 0.9576\n",
      "Epoch 232/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3179 - accuracy: 0.9280 - val_loss: 0.0881 - val_accuracy: 0.9619\n",
      "Epoch 233/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1996 - accuracy: 0.9322 - val_loss: 0.0887 - val_accuracy: 0.9725\n",
      "Epoch 234/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3653 - accuracy: 0.9364 - val_loss: 0.0846 - val_accuracy: 0.9682\n",
      "Epoch 235/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3298 - accuracy: 0.9237 - val_loss: 0.0843 - val_accuracy: 0.9682\n",
      "Epoch 236/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2386 - accuracy: 0.9492 - val_loss: 0.0841 - val_accuracy: 0.9682\n",
      "Epoch 237/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1350 - accuracy: 0.9407 - val_loss: 0.0875 - val_accuracy: 0.9597\n",
      "Epoch 238/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2020 - accuracy: 0.9449 - val_loss: 0.0869 - val_accuracy: 0.9703\n",
      "Epoch 239/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1706 - accuracy: 0.9449 - val_loss: 0.0862 - val_accuracy: 0.9682\n",
      "Epoch 240/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1983 - accuracy: 0.9364 - val_loss: 0.0955 - val_accuracy: 0.9449\n",
      "Epoch 241/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1781 - accuracy: 0.9237 - val_loss: 0.0845 - val_accuracy: 0.9661\n",
      "Epoch 242/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1354 - accuracy: 0.9470 - val_loss: 0.0825 - val_accuracy: 0.9746\n",
      "Epoch 243/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.2059 - accuracy: 0.9513 - val_loss: 0.0770 - val_accuracy: 0.9682\n",
      "Epoch 244/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2664 - accuracy: 0.9364 - val_loss: 0.0757 - val_accuracy: 0.9746\n",
      "Epoch 245/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2430 - accuracy: 0.9470 - val_loss: 0.0888 - val_accuracy: 0.9682\n",
      "Epoch 246/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1484 - accuracy: 0.9386 - val_loss: 0.0781 - val_accuracy: 0.9640\n",
      "Epoch 247/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2426 - accuracy: 0.9322 - val_loss: 0.0780 - val_accuracy: 0.9746\n",
      "Epoch 248/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2286 - accuracy: 0.9407 - val_loss: 0.0751 - val_accuracy: 0.9788\n",
      "Epoch 249/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2822 - accuracy: 0.9470 - val_loss: 0.0729 - val_accuracy: 0.9746\n",
      "Epoch 250/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.3260 - accuracy: 0.9470 - val_loss: 0.0763 - val_accuracy: 0.9703\n",
      "Epoch 251/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2322 - accuracy: 0.9258 - val_loss: 0.0927 - val_accuracy: 0.9428\n",
      "Epoch 252/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.3295 - accuracy: 0.9386 - val_loss: 0.0826 - val_accuracy: 0.9725\n",
      "Epoch 253/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.2129 - accuracy: 0.9407 - val_loss: 0.0834 - val_accuracy: 0.9703\n",
      "Epoch 254/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1617 - accuracy: 0.9428 - val_loss: 0.0871 - val_accuracy: 0.9513\n",
      "Epoch 255/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1324 - accuracy: 0.9492 - val_loss: 0.0929 - val_accuracy: 0.9597\n",
      "Epoch 256/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2436 - accuracy: 0.9492 - val_loss: 0.0738 - val_accuracy: 0.9597\n",
      "Epoch 257/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2636 - accuracy: 0.9364 - val_loss: 0.0917 - val_accuracy: 0.9492\n",
      "Epoch 258/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.3048 - accuracy: 0.9449 - val_loss: 0.0953 - val_accuracy: 0.9597\n",
      "Epoch 259/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.3196 - accuracy: 0.9470 - val_loss: 0.0692 - val_accuracy: 0.9767\n",
      "Epoch 260/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2410 - accuracy: 0.9301 - val_loss: 0.0769 - val_accuracy: 0.9597\n",
      "Epoch 261/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1730 - accuracy: 0.9513 - val_loss: 0.0708 - val_accuracy: 0.9788\n",
      "Epoch 262/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1693 - accuracy: 0.9343 - val_loss: 0.0724 - val_accuracy: 0.9661\n",
      "Epoch 263/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1260 - accuracy: 0.9470 - val_loss: 0.0677 - val_accuracy: 0.9703\n",
      "Epoch 264/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2132 - accuracy: 0.9470 - val_loss: 0.0670 - val_accuracy: 0.9725\n",
      "Epoch 265/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1898 - accuracy: 0.9470 - val_loss: 0.0677 - val_accuracy: 0.9788\n",
      "Epoch 266/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2051 - accuracy: 0.9492 - val_loss: 0.0741 - val_accuracy: 0.9576\n",
      "Epoch 267/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1907 - accuracy: 0.9407 - val_loss: 0.0681 - val_accuracy: 0.9703\n",
      "Epoch 268/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.2199 - accuracy: 0.9534 - val_loss: 0.0666 - val_accuracy: 0.9788\n",
      "Epoch 269/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2475 - accuracy: 0.9513 - val_loss: 0.0722 - val_accuracy: 0.9619\n",
      "Epoch 270/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.2537 - accuracy: 0.9322 - val_loss: 0.0655 - val_accuracy: 0.9852\n",
      "Epoch 271/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2061 - accuracy: 0.9555 - val_loss: 0.0643 - val_accuracy: 0.9788\n",
      "Epoch 272/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2301 - accuracy: 0.9555 - val_loss: 0.0634 - val_accuracy: 0.9788\n",
      "Epoch 273/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1330 - accuracy: 0.9470 - val_loss: 0.0640 - val_accuracy: 0.9788\n",
      "Epoch 274/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2549 - accuracy: 0.9492 - val_loss: 0.0641 - val_accuracy: 0.9788\n",
      "Epoch 275/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1515 - accuracy: 0.9492 - val_loss: 0.0696 - val_accuracy: 0.9661\n",
      "Epoch 276/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2057 - accuracy: 0.9364 - val_loss: 0.0655 - val_accuracy: 0.9703\n",
      "Epoch 277/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1794 - accuracy: 0.9407 - val_loss: 0.0693 - val_accuracy: 0.9809\n",
      "Epoch 278/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1984 - accuracy: 0.9534 - val_loss: 0.0666 - val_accuracy: 0.9703\n",
      "Epoch 279/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2288 - accuracy: 0.9343 - val_loss: 0.0641 - val_accuracy: 0.9746\n",
      "Epoch 280/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1203 - accuracy: 0.9619 - val_loss: 0.0712 - val_accuracy: 0.9725\n",
      "Epoch 281/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1906 - accuracy: 0.9301 - val_loss: 0.0823 - val_accuracy: 0.9534\n",
      "Epoch 282/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1456 - accuracy: 0.9343 - val_loss: 0.0636 - val_accuracy: 0.9788\n",
      "Epoch 283/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2242 - accuracy: 0.9407 - val_loss: 0.0618 - val_accuracy: 0.9767\n",
      "Epoch 284/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1375 - accuracy: 0.9470 - val_loss: 0.0694 - val_accuracy: 0.9640\n",
      "Epoch 285/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2797 - accuracy: 0.9449 - val_loss: 0.0625 - val_accuracy: 0.9809\n",
      "Epoch 286/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1176 - accuracy: 0.9597 - val_loss: 0.0611 - val_accuracy: 0.9767\n",
      "Epoch 287/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2576 - accuracy: 0.9386 - val_loss: 0.0593 - val_accuracy: 0.9831\n",
      "Epoch 288/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1537 - accuracy: 0.9555 - val_loss: 0.0648 - val_accuracy: 0.9703\n",
      "Epoch 289/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2193 - accuracy: 0.9470 - val_loss: 0.0605 - val_accuracy: 0.9725\n",
      "Epoch 290/500\n",
      "4/4 [==============================] - 0s 26ms/step - loss: 0.1929 - accuracy: 0.9407 - val_loss: 0.0772 - val_accuracy: 0.9725\n",
      "Epoch 291/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.2743 - accuracy: 0.9364 - val_loss: 0.0688 - val_accuracy: 0.9703\n",
      "Epoch 292/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1889 - accuracy: 0.9534 - val_loss: 0.0617 - val_accuracy: 0.9746\n",
      "Epoch 293/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2494 - accuracy: 0.9449 - val_loss: 0.0733 - val_accuracy: 0.9767\n",
      "Epoch 294/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1337 - accuracy: 0.9534 - val_loss: 0.0592 - val_accuracy: 0.9703\n",
      "Epoch 295/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2262 - accuracy: 0.9449 - val_loss: 0.0639 - val_accuracy: 0.9703\n",
      "Epoch 296/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.3547 - accuracy: 0.9322 - val_loss: 0.0534 - val_accuracy: 0.9809\n",
      "Epoch 297/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2947 - accuracy: 0.9386 - val_loss: 0.0606 - val_accuracy: 0.9788\n",
      "Epoch 298/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1255 - accuracy: 0.9597 - val_loss: 0.0634 - val_accuracy: 0.9725\n",
      "Epoch 299/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2481 - accuracy: 0.9428 - val_loss: 0.0587 - val_accuracy: 0.9788\n",
      "Epoch 300/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1085 - accuracy: 0.9534 - val_loss: 0.0562 - val_accuracy: 0.9809\n",
      "Epoch 301/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.2082 - accuracy: 0.9449 - val_loss: 0.0579 - val_accuracy: 0.9831\n",
      "Epoch 302/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1953 - accuracy: 0.9555 - val_loss: 0.0574 - val_accuracy: 0.9788\n",
      "Epoch 303/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1204 - accuracy: 0.9576 - val_loss: 0.0572 - val_accuracy: 0.9873\n",
      "Epoch 304/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1137 - accuracy: 0.9534 - val_loss: 0.0547 - val_accuracy: 0.9788\n",
      "Epoch 305/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1333 - accuracy: 0.9597 - val_loss: 0.0529 - val_accuracy: 0.9831\n",
      "Epoch 306/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1873 - accuracy: 0.9386 - val_loss: 0.0545 - val_accuracy: 0.9873\n",
      "Epoch 307/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1050 - accuracy: 0.9619 - val_loss: 0.0506 - val_accuracy: 0.9894\n",
      "Epoch 308/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1513 - accuracy: 0.9682 - val_loss: 0.0502 - val_accuracy: 0.9915\n",
      "Epoch 309/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1157 - accuracy: 0.9703 - val_loss: 0.0504 - val_accuracy: 0.9915\n",
      "Epoch 310/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1376 - accuracy: 0.9746 - val_loss: 0.0501 - val_accuracy: 0.9915\n",
      "Epoch 311/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1217 - accuracy: 0.9682 - val_loss: 0.0480 - val_accuracy: 0.9915\n",
      "Epoch 312/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1409 - accuracy: 0.9597 - val_loss: 0.0494 - val_accuracy: 0.9936\n",
      "Epoch 313/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1850 - accuracy: 0.9597 - val_loss: 0.0468 - val_accuracy: 0.9894\n",
      "Epoch 314/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1834 - accuracy: 0.9597 - val_loss: 0.0475 - val_accuracy: 0.9873\n",
      "Epoch 315/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0988 - accuracy: 0.9746 - val_loss: 0.0480 - val_accuracy: 0.9894\n",
      "Epoch 316/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1656 - accuracy: 0.9640 - val_loss: 0.0492 - val_accuracy: 0.9915\n",
      "Epoch 317/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1455 - accuracy: 0.9534 - val_loss: 0.0550 - val_accuracy: 0.9809\n",
      "Epoch 318/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1145 - accuracy: 0.9661 - val_loss: 0.0546 - val_accuracy: 0.9852\n",
      "Epoch 319/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1894 - accuracy: 0.9597 - val_loss: 0.0480 - val_accuracy: 0.9915\n",
      "Epoch 320/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1501 - accuracy: 0.9703 - val_loss: 0.0520 - val_accuracy: 0.9852\n",
      "Epoch 321/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1071 - accuracy: 0.9640 - val_loss: 0.0478 - val_accuracy: 0.9915\n",
      "Epoch 322/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1348 - accuracy: 0.9725 - val_loss: 0.0493 - val_accuracy: 0.9894\n",
      "Epoch 323/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1393 - accuracy: 0.9576 - val_loss: 0.0469 - val_accuracy: 0.9958\n",
      "Epoch 324/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1319 - accuracy: 0.9767 - val_loss: 0.0457 - val_accuracy: 0.9958\n",
      "Epoch 325/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2475 - accuracy: 0.9534 - val_loss: 0.0485 - val_accuracy: 0.9915\n",
      "Epoch 326/500\n",
      "4/4 [==============================] - 0s 13ms/step - loss: 0.1294 - accuracy: 0.9725 - val_loss: 0.0464 - val_accuracy: 0.9958\n",
      "Epoch 327/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1064 - accuracy: 0.9725 - val_loss: 0.0468 - val_accuracy: 0.9936\n",
      "Epoch 328/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1220 - accuracy: 0.9746 - val_loss: 0.0510 - val_accuracy: 0.9894\n",
      "Epoch 329/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.2698 - accuracy: 0.9555 - val_loss: 0.0485 - val_accuracy: 0.9936\n",
      "Epoch 330/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1314 - accuracy: 0.9746 - val_loss: 0.0511 - val_accuracy: 0.9873\n",
      "Epoch 331/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0630 - accuracy: 0.9788 - val_loss: 0.0475 - val_accuracy: 0.9958\n",
      "Epoch 332/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1449 - accuracy: 0.9640 - val_loss: 0.0504 - val_accuracy: 0.9915\n",
      "Epoch 333/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1556 - accuracy: 0.9682 - val_loss: 0.0627 - val_accuracy: 0.9746\n",
      "Epoch 334/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0823 - accuracy: 0.9661 - val_loss: 0.0464 - val_accuracy: 0.9979\n",
      "Epoch 335/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1307 - accuracy: 0.9661 - val_loss: 0.0541 - val_accuracy: 0.9809\n",
      "Epoch 336/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0640 - accuracy: 0.9809 - val_loss: 0.0456 - val_accuracy: 0.9915\n",
      "Epoch 337/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.3287 - accuracy: 0.9576 - val_loss: 0.0458 - val_accuracy: 0.9958\n",
      "Epoch 338/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1092 - accuracy: 0.9703 - val_loss: 0.0447 - val_accuracy: 0.9958\n",
      "Epoch 339/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1486 - accuracy: 0.9746 - val_loss: 0.0471 - val_accuracy: 0.9894\n",
      "Epoch 340/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1626 - accuracy: 0.9640 - val_loss: 0.0480 - val_accuracy: 0.9915\n",
      "Epoch 341/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1408 - accuracy: 0.9640 - val_loss: 0.0488 - val_accuracy: 0.9894\n",
      "Epoch 342/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1134 - accuracy: 0.9725 - val_loss: 0.0481 - val_accuracy: 0.9894\n",
      "Epoch 343/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1872 - accuracy: 0.9576 - val_loss: 0.0438 - val_accuracy: 0.9936\n",
      "Epoch 344/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2058 - accuracy: 0.9597 - val_loss: 0.0514 - val_accuracy: 0.9873\n",
      "Epoch 345/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1301 - accuracy: 0.9555 - val_loss: 0.0455 - val_accuracy: 0.9915\n",
      "Epoch 346/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1219 - accuracy: 0.9661 - val_loss: 0.0494 - val_accuracy: 0.9894\n",
      "Epoch 347/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.0691 - accuracy: 0.9852 - val_loss: 0.0454 - val_accuracy: 0.9894\n",
      "Epoch 348/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1831 - accuracy: 0.9682 - val_loss: 0.0417 - val_accuracy: 0.9958\n",
      "Epoch 349/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2543 - accuracy: 0.9619 - val_loss: 0.0483 - val_accuracy: 0.9915\n",
      "Epoch 350/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1502 - accuracy: 0.9640 - val_loss: 0.0469 - val_accuracy: 0.9852\n",
      "Epoch 351/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1528 - accuracy: 0.9449 - val_loss: 0.0432 - val_accuracy: 0.9958\n",
      "Epoch 352/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1968 - accuracy: 0.9513 - val_loss: 0.0523 - val_accuracy: 0.9915\n",
      "Epoch 353/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.2124 - accuracy: 0.9703 - val_loss: 0.0449 - val_accuracy: 0.9894\n",
      "Epoch 354/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1485 - accuracy: 0.9576 - val_loss: 0.0442 - val_accuracy: 0.9936\n",
      "Epoch 355/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0778 - accuracy: 0.9852 - val_loss: 0.0417 - val_accuracy: 0.9979\n",
      "Epoch 356/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0878 - accuracy: 0.9809 - val_loss: 0.0398 - val_accuracy: 0.9958\n",
      "Epoch 357/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0864 - accuracy: 0.9788 - val_loss: 0.0393 - val_accuracy: 0.9979\n",
      "Epoch 358/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1016 - accuracy: 0.9852 - val_loss: 0.0378 - val_accuracy: 0.9979\n",
      "Epoch 359/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1426 - accuracy: 0.9767 - val_loss: 0.0378 - val_accuracy: 0.9979\n",
      "Epoch 360/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1070 - accuracy: 0.9597 - val_loss: 0.0379 - val_accuracy: 1.0000\n",
      "Epoch 361/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1041 - accuracy: 0.9873 - val_loss: 0.0373 - val_accuracy: 1.0000\n",
      "Epoch 362/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1260 - accuracy: 0.9661 - val_loss: 0.0391 - val_accuracy: 0.9936\n",
      "Epoch 363/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1799 - accuracy: 0.9767 - val_loss: 0.0400 - val_accuracy: 0.9979\n",
      "Epoch 364/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0805 - accuracy: 0.9703 - val_loss: 0.0387 - val_accuracy: 0.9979\n",
      "Epoch 365/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1282 - accuracy: 0.9682 - val_loss: 0.0502 - val_accuracy: 0.9873\n",
      "Epoch 366/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1060 - accuracy: 0.9725 - val_loss: 0.0378 - val_accuracy: 0.9958\n",
      "Epoch 367/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1188 - accuracy: 0.9661 - val_loss: 0.0382 - val_accuracy: 0.9958\n",
      "Epoch 368/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1220 - accuracy: 0.9703 - val_loss: 0.0389 - val_accuracy: 0.9958\n",
      "Epoch 369/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1646 - accuracy: 0.9725 - val_loss: 0.0429 - val_accuracy: 0.9936\n",
      "Epoch 370/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1074 - accuracy: 0.9661 - val_loss: 0.0407 - val_accuracy: 0.9936\n",
      "Epoch 371/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1023 - accuracy: 0.9746 - val_loss: 0.0425 - val_accuracy: 0.9915\n",
      "Epoch 372/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1742 - accuracy: 0.9703 - val_loss: 0.0516 - val_accuracy: 0.9852\n",
      "Epoch 373/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1327 - accuracy: 0.9682 - val_loss: 0.0415 - val_accuracy: 0.9936\n",
      "Epoch 374/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1523 - accuracy: 0.9640 - val_loss: 0.0414 - val_accuracy: 0.9958\n",
      "Epoch 375/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0590 - accuracy: 0.9852 - val_loss: 0.0397 - val_accuracy: 0.9958\n",
      "Epoch 376/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1652 - accuracy: 0.9640 - val_loss: 0.0392 - val_accuracy: 0.9979\n",
      "Epoch 377/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1488 - accuracy: 0.9661 - val_loss: 0.0431 - val_accuracy: 0.9936\n",
      "Epoch 378/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.2070 - accuracy: 0.9640 - val_loss: 0.0499 - val_accuracy: 0.9767\n",
      "Epoch 379/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1209 - accuracy: 0.9640 - val_loss: 0.0438 - val_accuracy: 0.9894\n",
      "Epoch 380/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.2247 - accuracy: 0.9513 - val_loss: 0.0407 - val_accuracy: 0.9958\n",
      "Epoch 381/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0864 - accuracy: 0.9767 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1288 - accuracy: 0.9661 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0858 - accuracy: 0.9852 - val_loss: 0.0388 - val_accuracy: 0.9958\n",
      "Epoch 384/500\n",
      "4/4 [==============================] - 0s 25ms/step - loss: 0.1062 - accuracy: 0.9703 - val_loss: 0.0363 - val_accuracy: 0.9979\n",
      "Epoch 385/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1090 - accuracy: 0.9682 - val_loss: 0.0387 - val_accuracy: 0.9915\n",
      "Epoch 386/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0674 - accuracy: 0.9852 - val_loss: 0.0359 - val_accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1700 - accuracy: 0.9703 - val_loss: 0.0346 - val_accuracy: 0.9979\n",
      "Epoch 388/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0928 - accuracy: 0.9831 - val_loss: 0.0353 - val_accuracy: 0.9979\n",
      "Epoch 389/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1243 - accuracy: 0.9788 - val_loss: 0.0344 - val_accuracy: 0.9979\n",
      "Epoch 390/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0955 - accuracy: 0.9767 - val_loss: 0.0346 - val_accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0619 - accuracy: 0.9894 - val_loss: 0.0337 - val_accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0897 - accuracy: 0.9852 - val_loss: 0.0355 - val_accuracy: 0.9936\n",
      "Epoch 393/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1310 - accuracy: 0.9809 - val_loss: 0.0336 - val_accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1549 - accuracy: 0.9661 - val_loss: 0.0333 - val_accuracy: 0.9979\n",
      "Epoch 395/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1199 - accuracy: 0.9703 - val_loss: 0.0330 - val_accuracy: 0.9958\n",
      "Epoch 396/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1530 - accuracy: 0.9725 - val_loss: 0.0339 - val_accuracy: 0.9958\n",
      "Epoch 397/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1452 - accuracy: 0.9619 - val_loss: 0.0347 - val_accuracy: 0.9979\n",
      "Epoch 398/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0935 - accuracy: 0.9725 - val_loss: 0.0354 - val_accuracy: 0.9979\n",
      "Epoch 399/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.2176 - accuracy: 0.9555 - val_loss: 0.0363 - val_accuracy: 0.9958\n",
      "Epoch 400/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1325 - accuracy: 0.9682 - val_loss: 0.0358 - val_accuracy: 0.9979\n",
      "Epoch 401/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0993 - accuracy: 0.9619 - val_loss: 0.0347 - val_accuracy: 0.9979\n",
      "Epoch 402/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0952 - accuracy: 0.9703 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 403/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1636 - accuracy: 0.9746 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 404/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1130 - accuracy: 0.9746 - val_loss: 0.0328 - val_accuracy: 1.0000\n",
      "Epoch 405/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0933 - accuracy: 0.9746 - val_loss: 0.0334 - val_accuracy: 0.9979\n",
      "Epoch 406/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1400 - accuracy: 0.9767 - val_loss: 0.0332 - val_accuracy: 1.0000\n",
      "Epoch 407/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0691 - accuracy: 0.9894 - val_loss: 0.0317 - val_accuracy: 1.0000\n",
      "Epoch 408/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0945 - accuracy: 0.9703 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 409/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0845 - accuracy: 0.9831 - val_loss: 0.0323 - val_accuracy: 1.0000\n",
      "Epoch 410/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1335 - accuracy: 0.9767 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 411/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1389 - accuracy: 0.9682 - val_loss: 0.0329 - val_accuracy: 1.0000\n",
      "Epoch 412/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0696 - accuracy: 0.9746 - val_loss: 0.0415 - val_accuracy: 0.9831\n",
      "Epoch 413/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1677 - accuracy: 0.9513 - val_loss: 0.0381 - val_accuracy: 0.9894\n",
      "Epoch 414/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0781 - accuracy: 0.9767 - val_loss: 0.0389 - val_accuracy: 0.9958\n",
      "Epoch 415/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0906 - accuracy: 0.9767 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1892 - accuracy: 0.9513 - val_loss: 0.0400 - val_accuracy: 0.9915\n",
      "Epoch 417/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1211 - accuracy: 0.9725 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0892 - accuracy: 0.9703 - val_loss: 0.0344 - val_accuracy: 0.9979\n",
      "Epoch 419/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0692 - accuracy: 0.9809 - val_loss: 0.0317 - val_accuracy: 0.9958\n",
      "Epoch 420/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0817 - accuracy: 0.9746 - val_loss: 0.0331 - val_accuracy: 0.9936\n",
      "Epoch 421/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1400 - accuracy: 0.9767 - val_loss: 0.0307 - val_accuracy: 1.0000\n",
      "Epoch 422/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1388 - accuracy: 0.9852 - val_loss: 0.0306 - val_accuracy: 1.0000\n",
      "Epoch 423/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0687 - accuracy: 0.9831 - val_loss: 0.0316 - val_accuracy: 1.0000\n",
      "Epoch 424/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0886 - accuracy: 0.9767 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 425/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1215 - accuracy: 0.9746 - val_loss: 0.0296 - val_accuracy: 1.0000\n",
      "Epoch 426/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0832 - accuracy: 0.9831 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 427/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1011 - accuracy: 0.9725 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1600 - accuracy: 0.9661 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 429/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0953 - accuracy: 0.9767 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 430/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1571 - accuracy: 0.9661 - val_loss: 0.0309 - val_accuracy: 1.0000\n",
      "Epoch 431/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0716 - accuracy: 0.9725 - val_loss: 0.0333 - val_accuracy: 1.0000\n",
      "Epoch 432/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0512 - accuracy: 0.9873 - val_loss: 0.0330 - val_accuracy: 1.0000\n",
      "Epoch 433/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0976 - accuracy: 0.9788 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.9703 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 435/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1017 - accuracy: 0.9703 - val_loss: 0.0324 - val_accuracy: 0.9979\n",
      "Epoch 436/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1198 - accuracy: 0.9788 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
      "Epoch 437/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1357 - accuracy: 0.9788 - val_loss: 0.0294 - val_accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0657 - accuracy: 0.9894 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0577 - accuracy: 0.9873 - val_loss: 0.0287 - val_accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0960 - accuracy: 0.9873 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "4/4 [==============================] - 0s 27ms/step - loss: 0.1271 - accuracy: 0.9767 - val_loss: 0.0285 - val_accuracy: 1.0000\n",
      "Epoch 442/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1674 - accuracy: 0.9831 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1080 - accuracy: 0.9746 - val_loss: 0.0298 - val_accuracy: 0.9979\n",
      "Epoch 444/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0724 - accuracy: 0.9767 - val_loss: 0.0319 - val_accuracy: 1.0000\n",
      "Epoch 445/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0779 - accuracy: 0.9788 - val_loss: 0.0305 - val_accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.0601 - accuracy: 0.9852 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 447/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1510 - accuracy: 0.9703 - val_loss: 0.0321 - val_accuracy: 0.9979\n",
      "Epoch 448/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0679 - accuracy: 0.9746 - val_loss: 0.0274 - val_accuracy: 1.0000\n",
      "Epoch 449/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0555 - accuracy: 0.9767 - val_loss: 0.0293 - val_accuracy: 0.9979\n",
      "Epoch 450/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0834 - accuracy: 0.9703 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 451/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0912 - accuracy: 0.9831 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.0983 - accuracy: 0.9661 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1204 - accuracy: 0.9746 - val_loss: 0.0343 - val_accuracy: 0.9936\n",
      "Epoch 454/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.1013 - accuracy: 0.9703 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0876 - accuracy: 0.9619 - val_loss: 0.0359 - val_accuracy: 0.9958\n",
      "Epoch 456/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0737 - accuracy: 0.9809 - val_loss: 0.0315 - val_accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.1617 - accuracy: 0.9703 - val_loss: 0.0369 - val_accuracy: 0.9915\n",
      "Epoch 458/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1538 - accuracy: 0.9597 - val_loss: 0.0323 - val_accuracy: 0.9979\n",
      "Epoch 459/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0990 - accuracy: 0.9788 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 460/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0813 - accuracy: 0.9873 - val_loss: 0.0299 - val_accuracy: 0.9979\n",
      "Epoch 461/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1193 - accuracy: 0.9682 - val_loss: 0.0289 - val_accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1111 - accuracy: 0.9746 - val_loss: 0.0310 - val_accuracy: 1.0000\n",
      "Epoch 463/500\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 0.1088 - accuracy: 0.9788 - val_loss: 0.0315 - val_accuracy: 0.9979\n",
      "Epoch 464/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0925 - accuracy: 0.9767 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 465/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0712 - accuracy: 0.9788 - val_loss: 0.0348 - val_accuracy: 0.9936\n",
      "Epoch 466/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0685 - accuracy: 0.9831 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 467/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0923 - accuracy: 0.9852 - val_loss: 0.0327 - val_accuracy: 0.9915\n",
      "Epoch 468/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.1033 - accuracy: 0.9809 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 469/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.1059 - accuracy: 0.9788 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
      "Epoch 470/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.1199 - accuracy: 0.9746 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 471/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0487 - accuracy: 0.9915 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0626 - accuracy: 0.9767 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1078 - accuracy: 0.9703 - val_loss: 0.0267 - val_accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1217 - accuracy: 0.9788 - val_loss: 0.0246 - val_accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0826 - accuracy: 0.9831 - val_loss: 0.0255 - val_accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0942 - accuracy: 0.9746 - val_loss: 0.0321 - val_accuracy: 1.0000\n",
      "Epoch 477/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0756 - accuracy: 0.9767 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.1173 - accuracy: 0.9767 - val_loss: 0.0381 - val_accuracy: 0.9894\n",
      "Epoch 479/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0874 - accuracy: 0.9703 - val_loss: 0.0254 - val_accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.1442 - accuracy: 0.9725 - val_loss: 0.0288 - val_accuracy: 1.0000\n",
      "Epoch 481/500\n",
      "4/4 [==============================] - 0s 19ms/step - loss: 0.0615 - accuracy: 0.9852 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0563 - accuracy: 0.9788 - val_loss: 0.0258 - val_accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0825 - accuracy: 0.9809 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "4/4 [==============================] - 0s 18ms/step - loss: 0.0469 - accuracy: 0.9852 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "4/4 [==============================] - 0s 24ms/step - loss: 0.0744 - accuracy: 0.9809 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "4/4 [==============================] - 0s 22ms/step - loss: 0.1343 - accuracy: 0.9746 - val_loss: 0.0264 - val_accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "4/4 [==============================] - 0s 21ms/step - loss: 0.0550 - accuracy: 0.9788 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0538 - accuracy: 0.9809 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1111 - accuracy: 0.9767 - val_loss: 0.0259 - val_accuracy: 0.9979\n",
      "Epoch 490/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.1117 - accuracy: 0.9852 - val_loss: 0.0260 - val_accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "4/4 [==============================] - 0s 20ms/step - loss: 0.0347 - accuracy: 0.9958 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "4/4 [==============================] - 0s 23ms/step - loss: 0.0947 - accuracy: 0.9725 - val_loss: 0.0285 - val_accuracy: 0.9958\n",
      "Epoch 493/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0979 - accuracy: 0.9767 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 0.0559 - accuracy: 0.9894 - val_loss: 0.0245 - val_accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1188 - accuracy: 0.9831 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1411 - accuracy: 0.9682 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.1235 - accuracy: 0.9725 - val_loss: 0.0263 - val_accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 0.0960 - accuracy: 0.9746 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0799 - accuracy: 0.9703 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 0.0774 - accuracy: 0.9831 - val_loss: 0.0221 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "###########################################################\n",
    "\n",
    "# Fit with early stopping and model checkpoint to save the best models. \n",
    "# from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# # patient early stopping\n",
    "# es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "# mc = ModelCheckpoint('models/model-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)\n",
    "# # evaluate the model\n",
    "# history = model.fit(X_train, y_train ,verbose=1, epochs=500, batch_size=64,\n",
    "#                     validation_data=(X_test, y_test), callbacks=[es, mc])\n",
    "\n",
    "#Fit with no early stopping or other callbacks\n",
    "history = model_aro.fit(X_train, Y_aro,verbose=1, epochs=500, batch_size=128,\n",
    "                    validation_data=(X_test, Y_aro))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 1.0000\n",
      "Accuracy =  100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "\n",
    "_, acc = model_aro.evaluate(X_train, Y_aro)\n",
    "print(\"Accuracy = \", (acc * 100.0), \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://93660434-1c4a-4ef4-8de6-f71573b96a9c/assets\n"
     ]
    }
   ],
   "source": [
    "filenamearo = 'Arofinalized_model.sav'\n",
    "pickle.dump(model_aro, open(filenamearo, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEWCAYAAABhffzLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx7klEQVR4nO3deZgcZbX48e/pZfbJrNmTyUJCQgghIUOAgBBQIAKCV8QLAgKiQX4KyqJBvSou98JFLiBXUEE2ZVUR5SKyEyJbIDvZ92Qmy+xrZuvl/P7omsns05npns50n8/z9DNdb1fVe6oDZ945VfWWqCrGGGMShyvWARhjjBlclviNMSbBWOI3xpgEY4nfGGMSjCV+Y4xJMJb4jTEmwVjiNwlDRCaKiIqIJ8r9/FNEror0usZEith1/CaSRGQJcDwwSlWbYxxOByIyEdgJeFXV3+mz+naLaUAzEHCWr1PVpwYlyAgRkQXAk6o6LsahmCOQjfhNxDiJ9VOAAhf2sa57MGIKl6pmtL6APcDn2rW1Jf1o/7VgzGCwxG8i6SvAh8DjQIfyhYg8LiK/EZGXReQgcKaIHCMiS0SkWkTWi8iF7dZfIiJfa7d8tYi867wXEblXREpFpEZE1orITOez80VklYjUikiRiNw+kAMSkQUiUiwii0XkAPCYiOSIyEsiUiYiVc77ce22aYu9NW4RudtZd6eIfLaf604SkaUiUicib4jIAyLyZD+Oqbfv/TwR2eD0sVdEbnXa853jrBaRShH5l4hY/hii7B/ORNJXgKec17kiMrLT518G/hPIBJYB/we8BowAbgCeEpFpYfRzDnA6cDSQDfw7UOF8dtCJIxs4H7heRD7f3wNyjAJygQnAIkL/3zzmLBcAjcCve9n+JGAzkA/cBTwiItKPdZ8GPgLygNuBKw/3QETES+/f+yOESluZwEzgLaf9FqAYGA6MBH5A6C87MwRZ4jcRISKnEUqEf1LVFcB2Qom+vb+r6nuqGgRmAxnAnaraoqpvAS8Bl4XRnY/QL4/phM5TbVTV/QCqukRVP1HVoKquBZ4Bzhjg4QWBn6hqs6o2qmqFqj6vqg2qWkfol1lvfexW1YdVNQA8AYwmlDzDXldECoATgR8739e7wIv9OJaT6f179wEzRGSYqlap6sp27aOBCarqU9V/qZ0gHLIs8ZtIuQp4TVXLneWn6VTuAYravR8DFDm/BFrtBsb21ZGTrH4NPACUiMhDIjIMQEROEpG3nTJMDfANQqPngShT1abWBRFJE5HfichuEakFlgLZvZy3ONAu9gbnbcZhrjsGqGzXBh2/z3D19b1fDJwH7BaRd0TkFKf9l8A24DUR2SEit/Wjb3OEsMRvBkxEUoEvAWeIyAGnFn4TcLyIHN9u1fYjxH3A+E514gJgr/P+IKGra1qNat+nqt6vqnOBYwmVfL7rfPQ0oZHweFXNAn4L9FRWCVfnke0twDTgJFUdRqjsRAT66c1+IFdE2n8n4/uxn16/d1X9WFUvIlQG+hvwJ6e9TlVvUdXJwOeAm0Xk0/3o3xwBLPGbSPg8oUsfZxAq4cwGjgH+Raje3p1lhJL790TE61x++DngWefz1cAXnNH1FODa1g1F5ERnZO919tHEoUsvMwmNjJtEZB5dy02RkEmorl8tIrnAT6LQRwequhtYDtwuIknOSPxzfW0nIintX4TOEXT7vTv7vVxEslTVB9TifK8icoGITHHON7S2B7rr0xz5LPGbSLgKeExV96jqgdYXoXLM5dLNJZCq2kLoks/PAuXAg8BXVHWTs8q9QAtQQqjW3f46+mHAw0AVoTJFBXC389n/A34mInXAj3FGrBF2H5DqxP0h8EoU+ujO5cAphI73F8BzhO436MlYQr+g2r/G0/v3fiWwyylhfQO4wmmfCrwB1AMfAA+q6pJIHZgZXHYDlzFDlIg8B2xS1aj/xWHii434jRkinBLXUSLiEpGFwEWE6vDGHBa7C9GYoWMU8FdC1/EXA9er6qrYhmSGIiv1GGNMgrFSjzHGJJghUerJz8/XiRMnxjoMY4wZUlasWFGuqsM7tw+JxD9x4kSWL18e6zCMMWZIEZHd3bVbqccYYxKMJX5jjEkwlviNMSbBDIkavzHmyOLz+SguLqapqanvlU3UpaSkMG7cOLxeb1jrW+I3xhy24uJiMjMzmThxIj0/U8YMBlWloqKC4uJiJk2aFNY2Vuoxxhy2pqYm8vLyLOkfAUSEvLy8w/rryxK/MaZfLOkfOQ733yKuE395+Uvs3n1nrMMwxpgjSlwn/srKf1JUdHffKxpjhpSKigpmz57N7NmzGTVqFGPHjm1bbmlp6XXb5cuXc+ONN/bZx/z58yMS65IlS7jgggsisq9IieuTu6FHoAb7XM8YM7Tk5eWxevVqAG6//XYyMjK49dZb2z73+/14PN2nt8LCQgoLC/vs4/33349IrEeiuB7xgwtVezqcMYng6quv5uabb+bMM89k8eLFfPTRR8yfP585c+Ywf/58Nm/eDHQcgd9+++189atfZcGCBUyePJn777+/bX8ZGRlt6y9YsIAvfvGLTJ8+ncsvv5zWWY1ffvllpk+fzmmnncaNN954WCP7Z555huOOO46ZM2eyePFiAAKBAFdffTUzZ87kuOOO49577wXg/vvvZ8aMGcyaNYtLL710wN9V3I/4LfEbE11bt36H+vrVEd1nRsZspk6977C327JlC2+88QZut5va2lqWLl2Kx+PhjTfe4Ac/+AHPP/98l202bdrE22+/TV1dHdOmTeP666/vcj38qlWrWL9+PWPGjOHUU0/lvffeo7CwkOuuu46lS5cyadIkLrvssrDj3LdvH4sXL2bFihXk5ORwzjnn8Le//Y3x48ezd+9e1q1bB0B1dTUAd955Jzt37iQ5ObmtbSDiesRvpR5jEssll1yC2+0GoKamhksuuYSZM2dy0003sX79+m63Of/880lOTiY/P58RI0ZQUlLSZZ158+Yxbtw4XC4Xs2fPZteuXWzatInJkye3XTt/OIn/448/ZsGCBQwfPhyPx8Pll1/O0qVLmTx5Mjt27OCGG27glVdeYdiwYQDMmjWLyy+/nCeffLLHEtbhiOsRv5V6jIm+/ozMoyU9Pb3t/Y9+9CPOPPNMXnjhBXbt2sWCBQu63SY5Obntvdvtxu/3h7XOQB5i1dO2OTk5rFmzhldffZUHHniAP/3pTzz66KP84x//YOnSpbz44ov8/Oc/Z/369QP6BRD3I35L/MYkppqaGsaOHQvA448/HvH9T58+nR07drBr1y4AnnvuubC3Pemkk3jnnXcoLy8nEAjwzDPPcMYZZ1BeXk4wGOTiiy/m5z//OStXriQYDFJUVMSZZ57JXXfdRXV1NfX19QOKPa5H/FbqMSZxfe973+Oqq67innvu4ayzzor4/lNTU3nwwQdZuHAh+fn5zJs3r8d133zzTcaNG9e2/Oc//5k77riDM888E1XlvPPO46KLLmLNmjVcc801BIOhvHXHHXcQCAS44oorqKmpQVW56aabyM7OHlDsQ+KZu4WFhdqfB7Hs3Hk7u3f/lDPOCNpdhsZE0MaNGznmmGNiHUbM1dfXk5GRgaryzW9+k6lTp3LTTTfFJJbu/k1EZIWqdrl2NWqlHhF5VERKRWRdN5/dKiIqIvnR6j/UT+gkj5V7jDHR8PDDDzN79myOPfZYampquO6662IdUliiWep5HPg18If2jSIyHjgb2BPFvp2+3M47K/cYYyLvpptuitkIfyCiNuJX1aVAZTcf3Qt8DxiEGpPLicVG/MZE2lAoEyeKw/23GNSrekTkQmCvqq4JY91FIrJcRJaXlZX1sz8r9RgTDSkpKVRUVFjyPwK0zsefkpIS9jaDdlWPiKQBPwTOCWd9VX0IeAhCJ3f712drqccSvzGRNG7cOIqLi+nvoMxEVusTuMI1mJdzHgVMAtY4V9iMA1aKyDxVPRCdLltLPVbjNyaSvF5v2E97MkeeQUv8qvoJMKJ1WUR2AYWqWh6tPq3UY4wxXUXzcs5ngA+AaSJSLCLXRquvnmOwUo8xxnQWtRG/qvY6Y5GqToxW34dYqccYYzqL+7l6wEo9xhjTXkIkfiv1GGPMIQmR+K3UY4wxh8R14rc7d40xpqu4TvxW6jHGmK4SIvFbqccYYw6J68RvpR5jjOkqrhO/lXqMMaarhEj8VuoxxphD4jrxW6nHGGO6iuvEb6UeY4zpKiESv5V6jDHmkLhO/FbqMcaYruI68VupxxhjukqIxG8jfmOMOSSuE7/Nx2+MMV3FdeK3Uo8xxnSVEInfSj3GGHNINJ+5+6iIlIrIunZtvxSRTSKyVkReEJHsaPUfYqUeY4zpLJoj/seBhZ3aXgdmquosYAvw/Sj2b6UeY4zpRtQSv6ouBSo7tb2mqn5n8UNgXLT6Byv1GGNMd2JZ4/8q8M+ePhSRRSKyXESWl5WV9bMLu3PXGGM6i0niF5EfAn7gqZ7WUdWHVLVQVQuHDx/ez35aD89G/MYY08oz2B2KyFXABcCnVVWj25eVeowxprNBTfwishBYDJyhqg3R79FKPcYY01k0L+d8BvgAmCYixSJyLfBrIBN4XURWi8hvo9V/KAYr9RhjTGdRG/Gr6mXdND8Srf66Y6UeY4zpKq7v3LVSjzHGdBXXid9KPcYY01WcJ34r9RhjTGdxnfgPlXos8RtjTKu4TvyHSj1W4zfGmFZxnvhtxG+MMZ3FdeK3Uo8xxnQV14nfSj3GGNNVnCd+G/EbY0xncZ34rdRjjDFdHVbiF5EcEZkVrWAizUo9xhjTVZ+JX0SWiMgwEckF1gCPicg90Q9t4FoTv434jTHmkHBG/FmqWgt8AXhMVecCn4luWJHktsRvjDHthJP4PSIyGvgS8FKU44k4tzuNQKA21mEYY8wRI5zE/zPgVWCbqn4sIpOBrdENK3LS0o7h4MENsQ7DGGOOGH3Ox6+qfwb+3G55B3BxNIOKpPT046ioeDHWYRhjzBEjnJO7dzknd70i8qaIlIvIFYMRXCRkZByHz1dGS0tprEMxxpgjQjilnnOck7sXAMXA0cB3+9pIRB4VkVIRWdeuLVdEXheRrc7PnH5HHiavdwQAfn9VtLsyxpghIZzE73V+ngc8o6qVYe77cWBhp7bbgDdVdSrwprMcVS5XMgDBYHO0uzLGmCEhnMT/fyKyCSgE3hSR4UBTXxup6lKg8y+Ji4AnnPdPAJ8PP9T+EUkCLPEbY0yrPhO/qt4GnAIUqqoPOEgogffHSFXd7+x3PzCin/sJW+uIX7Ul2l0ZY8yQ0OdVPSLiBa4EThcRgHeA30Y5LkRkEbAIoKCgoN/7sVKPMcZ0FE6p5zfAXOBB53WC09YfJc7NYDg/e7zURlUfUtVCVS0cPnx4P7trX+qxEb8xxkAYI37gRFU9vt3yWyKypp/9vQhcBdzp/Px7P/cTtkOlHhvxG2MMhDfiD4jIUa0Lzp27fU5+IyLPAB8A00SkWESuJZTwzxaRrcDZznJUuVx2ctcYY9oLZ8T/XeBtEdkBCDABuKavjVT1sh4++nT44Q2cSGuN30o9xhgD4U3Z8KaITAWmEUr8m3QI1U2s1GOMMR31mPhF5As9fHSUiKCqf41STBF1qNRjI35jjIHeR/yf6+UzBYZE4j9U6rERvzHGQC+JX1X7rOMPBVbqMcaYjuL8YetW6jHGmM7iPvGLuAG3lXqMMcYR94kfQqN+m6vHGGNCwnkQy3IR+eZgzJ0fLS5Xso34jTHGEc6I/1JgDPCxiDwrIueKM1vbUCFiid8YY1qFMy3zNlX9IaEnbz0NPArsEZGfikhutAOMBJ+vhP37f0d5edSnBjLGmCNeWDV+EZkF/A/wS+B54ItALfBW9EKLvNLSP8U6BGOMiblw5uNfAVQDjwC3tZuuYZmInBrF2CIuKWl0rEMwxpiYC2eStktUdUd3H6hqT9M6HJG83vxYh2CMMTEXTqmnRkTuF5GVIrJCRH4lInlRjywq+pxN2hhj4l44if9ZoAy4mFBtvwx4LppBRZrbPQyAYLDPZ8QbY0zcCyfx56rqz1V1p/P6BZAd5bgiav78fYAlfmOMgfAS/9sicqmIuJzXl4B/RDuwSHK70/F4ci3xG2MM4SX+6whdv9/ivJ4FbhaROhGpjWZwkeRypRAINMY6DGOMiblwnsCVGelOReQm4GuE5vX/BLhGVaM6HHe5UmzEb4wxhH8D14UicrfzumAgHYrIWOBGoFBVZwJuQtNCRJXLlYLPV2LTMxtjEl44k7TdCXwb2OC8vu20DYQHSBURD5AG7Bvg/vrkcqVSVfUGn3xyYbS7MsaYI1o4N3CdB8xW1SCAiDwBrAJu60+HqrpXRO4G9gCNwGuq+lrn9URkEbAIoKCgoD9ddeByeQGoqnp1wPsyxpihLNz5+LPbvc8aSIfO9M4XAZMIzfqZLiJXdF5PVR9S1UJVLRw+fPhAugTsUk5jjGkVzoj/v4BVIvI2IMDpwPcH0OdngJ2qWgYgIn8F5gNPDmCffQoEDkZz98YYM2T0mvhFxAUEgZOBEwkl/sWqemAAfe4BThaRNEKlnk8Dywewv7BY4jfGmJBeE7+qBkXkW6r6J+DFSHSoqstE5C/ASsBP6HzBQ5HYd2+CwYZod2GMMUNCOKWe10XkVkLz87QNm1W1sr+dqupPgJ/0d/v+ODTiT4jHDBtjTI/CSfxfdX5+s12bApMjH070qPqA0PN3jTEmkYWT+I/pfFetiKREKZ6o8XpH4vOVIOKOdSjGGBNT4dQ93g+z7Yh2wgkfkJZ2DIFAA6oa63CMMSZmekz8IjJKROYSusN2joic4LwWELrbdkhJTZ3EyJFXAkGCweY+1zfGmHjVW6nnXOBqYBxwT7v2OuAHUYwpatzuDAACgXrc7iFXrTLGmIjoMfGr6hPAEyJysao+P4gxRU37xA/2/F1jTGIK5+TuSyLyZWBi+/VV9WfRCipaOiZ+Y4xJTOEk/r8DNcAKYEgXx12uUHnH5u0xxiSycBL/OFVdGPVIBkHrNfyqQ/r3lzHGDEhYl3OKyHFRj2QQtCZ+u6rHGJPIwhnxnwZcLSI7CZV6BFBVnRXVyKJAJAnAnsJljElo4ST+z0Y9ikFipR5jjAmj1KOqu4HxwFnO+4ZwtjsSWanHGGPCe+buT4DFHHr4ipcoPzQlWqzUY4wx4Y3c/w24EGdKZlXdB2RGM6hosVKPMcaEl/hbNDSrmQKISHp0Q4oeK/UYY0x4if9PIvI7IFtEvg68ATwc3bCi41CpxxK/MSZx9XlVj6reLSJnA7XANODHqvp61COLgtYRf0vLPiorXyU399wYR2SMMYMvrKtzVPV1Vf0usCQSSV9EskXkLyKySUQ2isgpA91nOFoTf1HR3axdu9BO8hpjEtLhXpYZqYnZfgW8oqrTgeOBjRHab69CT9869AQuK/kYYxLR4SZ+GWiHIjIMOB14BEBVW1S1eqD7DZfLldT23hK/MSYRHW7ivy4CfU4GyoDHRGSViPy+uyuFRGSRiCwXkeVlZWUR6Dak/cPW7bJOY0wiCucGrktEpPW6/XNF5K8icsIA+vQAJwC/UdU5hO4PuK3zSqr6kKoWqmrh8OHDB9BdRyKHEr+N+I0xiSicEf+PVLVORE4DzgaeAH4zgD6LgWJVXeYs/4XQL4JBYaUeY0yiCyfxB5yf5wO/VdW/A0m9rN8rVT0AFInINKfp08CG/u7vcLUv9dgDWYwxiSic2Tn3OjdwfQb4bwnVSgY6SdsNwFMSuqNqB3DNAPcXNiv1GGMSXTiJ/0vAQuBuVa0WkdHAdwfSqaquBgoHso/+al/qsZO7xphEFE7iHw38Q1WbRWQBMAv4QzSDiqaOpR5L/MaYxBNOyeZ5ICAiUwhdez8JeDqqUUWRlXqMMYkunMQfVFU/8AXgPlW9idBfAUOSjfiNMYkunMTvE5HLgK8ALzlt3uiFFF1u96F7xeyqHmNMIgon8V8DnAL8p6ruFJFJDNEncAF4vYduBtu06Up8vooYRmOMMYMvnGfubgBuBT4RkZmEbr66M+qRRUn7xA+wf//vYxSJMcbERp9X9ThX8jwB7CI0Sdt4EblKVZdGNbIoSUoa0anF3e16xhgTr8K5nPN/gHNUdTOAiBwNPAPMjWZg0eL15ndYFhnovWjGGDO0hJP1vK1JH0BVtzCkT+4O67CsGuhhTWOMiU/hjPhXiMgjwB+d5cuBFdELKbo8nswOy35/TYwiMcaY2Agn8X8D+CZwI6Ea/1LgwWgGFU0pKZM7LPv91bEJxBhjYqTXxC+hAvgKVZ0J3DM4IUVXSsp4Tj55Fx9+OBGAffseICtrPiNHfjm2gRljzCDptcavqkFgjYgUDFI8gyIlZUKH5d27fxGjSIwxZvCFO0nbehH5iNDTsgBQ1QujFtUgGDbsVGpr3wMgJWVSjKMxxpjBE07i/2nUo4iBE054lyVLQs+O93iyYhyNMcYMnh4TvzMb50hVfadT++nA3mgHNhhmz36H1avPwO+vinUoxhgzaHqr8d8H1HXT3uB8NuRlZ59OTs45+HyW+I0xiaO3xD9RVdd2blTV5cDEgXYsIm4RWSUiL/W9dvR4vbn4/ZWxDMEYYwZVb4k/pZfPUiPQ97eBjRHYz4B4PDkdSj2BQBPBYEsMIzLGmOjqLfF/LCJf79woItcywDt3RWQccD4Q86kxPZ5cfL4qVBWAd9/NZtmyqRw8uIkVK07C56uObYDGGBNhvV3V8x3gBRFpP0VDIZAE/NsA+70P+B6Q2dMKIrIIWARQUBC92wi83lwggN9fjdebg2ozzc172LXrJ9TVfURl5ct2c5cxJq70mPhVtQSYLyJnAjOd5n+o6lsD6VBELgBKVXWFM+VzT/0/BDwEUFhYqAPpszdpadMAKCq6G5frUHWr9b09ntEYE2/6vI5fVd8G3o5gn6cCF4rIeYTOIwwTkSdV9YoI9hG2jIzZAOzZ818d2lufzRsMNrN0aSojRnyZ6dMfGezwjDEm4gZ9MnpV/b6qjlPVicClwFuxSvoASUlj8HjyurS3Jn7VZoLBJg4ceHSwQzPGmKhI+KeQiEjbqL9jexJgs3caY+JPTBO/qi5R1QtiGQPQbeIPBELTEjU3x8VNysYY0ybhR/xwKPFnZp5EevosAHy+EgCamnbHKixjjIkKS/xATs6ZpKXN4Jhj/sDYsTcA0NJiid8YE5/CmZ0z7iUnj2XevPUA1NevAqCl5QAAzc2W+I0x8cVG/J243RkANDXtBCAYbIplOMYYE3GW+Dtxu3u8mZjKylcHMRJjjIkOS/ydtF7G2Z21axcOYiTGGBMdlvg7SU+fidc7PNZhGGNM1Fji78TjyeDkk3f2+Hkw6EdVWbfui1RWvjaIkRljTGRY4u+G251OQcH3ycu7qMtnfn8V9fUrKS9/nrVrz41BdMYYMzCW+HswefJ/kZ9/YZf2AwceY8WKwhhEZIwxkWGJvxfdXeFTURHTJ0UaY8yAWeLvRes1/e3ZnbzGmKHOEn8vuhvxNzfv6bCsGhyscIwxJiIs8ffC7U4HwOVKJzNzXrfrtLSUDmZIxhgzYJb4eyUAZGd/irlzlzFy5JVd1vD7KwY7KGOMGRBL/L3IyDieo466m+nT/wjA+PG3dFnH57PEb4wZWizx90JEGD/+FpKS8oHQL4LTT+/48HWfr5KPPjqGoqJ7ut1HMOhjyRJh376Hox6vMcaEwxL/YXK5Os7l09y8h4aGTWzfHvproK5uJe++m0dz834gdMMXwI4diwc3UGOM6cGgJ34RGS8ib4vIRhFZLyLfHuwYIungwfUdlnfv/k/8/kqqq5cAEAw2xiAqY4zpWSwexOIHblHVlSKSCawQkddVdUMMYumX5OTxNDcXIZLEwYPr2to/+mhG2wNcXK5U4NCze0EHO0xjjOnWoI/4VXW/qq503tcBG4Gxgx3HQBQWruXkk4vwenM7jPgbGja2lXYCgRrnZ/1h7fvgwU0Eg819r2iMMf0U0xq/iEwE5gDLuvlskYgsF5HlZWVlgx5bb7zebFJSxuHx5LUl+NYRfiufr/UXQGviF2pq3qem5sMe9+vzVfHxx8ewefOiqMRtjDEQw8QvIhnA88B3VLW28+eq+pCqFqpq4fDhR+b8+Dk5Z7W9nz9/PxMm/KRtuaVlP42N29sSv99fxapVp7Jq1Snd7quhYSsffDAOsCd9GWOiKyaJX0S8hJL+U6r611jEEAkFBbeRmXkSY8d+C48ni0mTbuf005txudIoKrqLZcum0NCwpct2ql3r/UVFvyQYbHA+90U9dmNM4orFVT0CPAJsVNXuL34fIpKTxzB37odMnfq/bW0uV1JbAgfYseO7Xbbr7kqf1nMDofc1bNt2M35/lz+EjDFmwGIx4j8VuBI4S0RWO6/zYhBH1Hm9I7ttb5/kN236Ku+9N6pTeSdAcfG9FBX9MsoRGmMS0aBfzqmq79I6CU6cO/HEdbz/ftfzEytXzmfu3OU0Nm7hwIHHetw+GGyKZnjGmAQVi+v4496YMd+koWEjXm9et583N+9hxYrCLlM8d1ZUdDfDh19CUtIYmpv3kJU1PxrhGmMSjCX+KDj66F/3uU5r0j/22OfZtu1mmpu7f8DLypUntb1fsMBuAjPGDJzN1TOIkpMLOiwXFNzG8OFfwOVKCWt7v78uGmEZYxKMjfij7Pjj36S29gNU/eTkfIZVq04DIDl5Avn5/wZAIBBeQm9q2k19/Wry8y/E4xl2WHFUV/+LkpI/cPTRDxG6sMoYk6gs8UdZTs5ZbTd6BYMtbe2nnLKr7X13iX/s2BvwevPZtevQTWHLlx8HwMSJPycv7zwyMo5HxB1WHKtXnw7AUUfdi8fT9VnCxpjEYaWeQeRyJTF+/GLmzHm/Q3tm5twOy3PmvMfUqfczceKPEen6u3nv3vtZsWIun3xy4WHH4PdXH/Y2xpj4Yol/kB111J1kZXWctuHYY59nzpz32pbbX71z6qmVnHLK/rblnJxz8PlCcxdVVb3e5WHvJSVPsWHDl9vaVbXD3cOW+I0xlviPAF5vbo+Xano8mSQnjwJg1KhryMwsbPtM1ceKFSeiGsDvr6eq6i22br2B0tJnKCl5CoCtW2/go4+mtW3TmviDQT/79z9mM4Eak4As8Q8Rp5/ezLRpv2fcuNBza4YNOxmA+vqVVFS8xNq157BmzafbJoUrLX2aQKCJffse6LCfmpp3ANi//2E2b/4qRUX3htV/Y+N2amre73tFY8wRz07uHkFycs6hru7jbj9rfeRjUtIITjutDgjy7rs5QJB16z7ftl7rBG9VVW9TWfnPLvvZufM/2Lfvd20Pia+qep0JE25r+7yk5BlUA4wadQUAgUADjY1bWb58NgBnnBG0q4KMGeIs8R9Bjj8+vOmYW6/KOeMMP++8E/qjbe7cFfj9NaxZczYTJvyQ3bt/xpYt3+h2++bmorb3dXXLOXDgCRobt5OUNJodO75PUtIoRo26AlVl8+ZrKS19tm39pqbdpKZO7OcRGmOOBJb4hzAR4cQT1+Px5JCcPBqA006rwuVKZs+e/8LnK2X06OvYv/93Hbbzeoczbty3EfGwY8dtbNp0dYfPGxvrqax8lfXrL+lyqWld3XJUfaSmHoVI75VCVUVE2n52JxBowO1OO8wjN8YMhCX+IS49fUaHZY8nE4CCgh9SV7eMCRP+o0viP/XUUgBKS5/rYa8B1q5d2O0nGzZcAkBe3gW4XCmkpk5j8uRfAKEHz6emHo3L5aW09Dm2bbuF3NyzKSl5iqlTf82YMYeeLNbYuIPq6rfZvPlrnHjiBsrL/0pKykRGjrz8sL8DY8zhscQfpyZNur3PddpPIXHSSds4cOAJQNi9+2dd1s3ImMuYMYvYsuU6ACoqXmr7TMTDsGEn88knn6Wg4Aekph7F5s3XAnDgwOMAlJU9z+jRX2fHjsWkph7Nli1fb9t+48YrqK9fCRBW4m9pKaW8/EWamnaSl/c5srJCJ7pVA2Hf0GZMIpPungZ1pCksLNTly5fHOowhq6TkKfz+GjIyTiApaVRbjb6pqZgPPxwPHJoAzuer5L338hgz5v8xduwNbN9+C253GiNGXM7w4Z+npORpPJ5sDhx4nNzcc9m27Ts9PlA+ObmgwwykI0Zc2uF8QU7OuVRVdTyvMWvW62RmnkB9/Sqysj5FU9MuVIOkp0+nrm4Ffn8da9ac2WGbefO20Ni4nU8+OZ/Ro69l2rSHOnze0LAVn6+U1NSpJCWN6PP7Ug3Q0lJCcvKYPtcdTK33ZvRVYjOmlYisUNXCLu2W+BOXaoB33vEwduwNTJ16f7v2nmvynVVXv8v27TfT1LQbn6+0rX3OnPfxeIbx8cczmTLlV+zYcVuXJ4+FTk73/EfnyJFfoaTkDwAMH/5Fysr+0u16LlcKbvcwfL5SXK5UCgtXU1x8L2PH3khq6lSWLvW2rTt37goyMuYQDDYRCNRTVfUmGRnHk55+DACVlW+wc+d/UFe3jKOPfpgxY77WY3z79z9KdfXbuFzpHH30g4i4qKpaQkXFSxQULCYpqX/Pig4G/bhch76X1n+PrVu/TWXlq5xwwod4vdn92ndfysr+RmPjFgoKvheV/ZvBZYnfdCsQaMTlSo7IKLKxcQdlZX9h1KhruiS9QOAgPl8VwWAjO3Z8j5SUo5gy5W6WLAn9gsnMPLHHS1nbS0oaxciRV5KSMoG9ex+koWFDj+u63Rmkph7dVkYCGDZsPk1Nu2hp2ddh3ZSUSaSkTKK6+q22No8nj5NP3tV2FVVFxSts334r+fkXUVe3osNfK7NmvUZl5asUF/8PACNGXMaMGU/T1FSE15tHc/M+9uy5A7+/htzchdTULGXMmG+QmTmPqqrXGDZsPiJCcfGv2LXrJ2RknMCECT+ipOSP1NS8x6hRV1JUdDcAycnjmTLlPnJyPo3Hk9Xnd9bZ7t13kp29gMbGzezb9zvmzPlXW4ms9d/j9NNbcLm8qCrBYCNudxoNDVsoKrqbyZPvIhhsxOPJxu1OPez+VZVAoJb6+k/Izj4trG2am/fhcqXi9eYcdn+J7IhK/CKyEPgV4AZ+r6p39ra+Jf74VVHxT1pa9jN69FepqnqLxsZtjBmzyCnpnE1+/kUUFCymqOgesrLmd7nDORj04fNV8MEHoyko+CEtLQdQ9ZGdfQZFRffQ0LCRSZN+RkHBD9i+/WaKi+8DIDt7AT5fBQcPftJtXCkpE2lq2tW27PWOxOcr6bBOTs651Na+16HUlZ9/Mampkykq+iUpKZNpatrRbgsX0HGKjYGaMuV/EfFQWfkyo0d/nfT0mTQ2bmPnzh+RkjKB9PSZ+P1VNDZuY8qU+6iuXuKcf3EDAQBmzHiOQKCevLzzef/90F3io0d/nZycs9m799fU1i5jzpx32bTpShoaNiHiRdVHTs5nmDXrVUA4eHAd6enHsmfPHXi9Ixg16mpU/ezb9yBZWZ/iwIHHSEs7Frc7jZ07f0xLy14ACgvXkJExi2CwmV27bmfMmOtJSSlANUhFxcuotqDqY8OGS/F6h1NYuNYZXFxNIFBPcvIompv34/OVUlb2VzIyZrNv32+ZMeNZPJ4s6utXkZZ2DG53GsGgn9LSp3G708nMPJHk5PEEAgedbzKAx5NFZeXrNDXtYMyY62hpKaWxcUfbOaRWTU3FlJT8keHDv0Ba2jTCFQz6aGraRVraVGe5BVBcruQO6/l8FQQC9aSkTDjc/xy6OGISv4SGFluAs4Fi4GPgMlXtcehmid/0pbu/XILBZlpaSkhJCZ3Erqn5kFWrTmHcuJuYMuUeVIMEAnX4fFVAgN27f0Fa2jGkpEx0ptD+FA0NG0hOLsDnKyMYbGT69D+yadOVTJlyP2PHfhMRF+XlL7Fu3edwudI49dRyRFxs2HAp5eV/A2Ds2BvxeLIZM2YRTU27WbXq1LYYhw2bT21tz3dEjx37LdzuTPbsuQOPJ5fc3HMpLX0mKt/h4fB48vD7K8jKOg2PJ5uKipe6+eV46JdLb5KTJ3R4EFFWVmgm2ZqapX1uG/pLcTnQMY9lZZ3uxPViWx/BYEPbPFcuVxqZmSdSU/MOIh683hHk51/Evn2/AUKz4+7d+78ATJ58F83NRVRVvY7bnUFd3SoggMuVRlLSCFyudDIz55KdfTrV1e+0/eWak/MZysqeJyPjePz+amprP2zbn9ebR1FR6K/D1NSptLTsJTV1Co2N29u2z8//N3JyziYv7/y2/4YP15GU+E8BblfVc53l7wOo6h09bWOJ30SKz1fR4yMxu65bjd9fSWrqZHy+ClpaSklPPwafrxKvN7fDuo2NOwgGmzpcXltbuwyXK42MjOM6rNvUVEQgUE9q6lG4XEn4fJWUl79IXt55+P1VNDRswuVKJzt7QVut/+DBDXg8ubhcyVRU/B+1tcsYM+Z6Skr+SFLSCJqb99LcXERa2gySkkaSn/95tm+/lZycz9DUtIvMzHmUl79Abu5CkpJGUln5CoFAPSIeiovvJSNjDvX1q4BQwho//ru0tJQQCNSSnb2A9eu/RHPzHk4+eReqfrzeEaxbdxEVFS/h8eSSnDyOpKRRJCePo7z8BZKSRpOdvQCPJ4u6uuVkZZ3G3r3/i89Xxpw579LQsJUDBx6npuYdkpPHt91UmJxcQEvLflSDjB9/i/NvJW3nYiorXyEpaRR1dcvx+ysByMiYTX39aiB0vicv7yIqK18mEKgjLW1GWznQ48nG48nu8JdcZuY80tKmO3NbBRgx4sv4/TVUVv6jw7+Zy5VORsZxBINN1NevZuTIK6mt/YhgsJH09BnU1n6E31+Jx5PLsGEntd01HzqeA6i2EK6kpNGMGPFl9u//PYFADbNmvUZu7tlhb9/ekZT4vwgsVNWvOctXAiep6rc6rbcIWARQUFAwd/fu7h9NaIzpP1WlsXEraWlHo6pOyWZml5P7oYkAqzv80lQNEAz6cLtTOq0b7PacUSBwkIMH1zNs2Lwun/n9tYDi8WTR1FREMNjUVhLpSUtLKW53Jm53Kn5/DS5X6HyDy5WE31+H319FSkoBjY07SUkp6HCpb1XVW4h4yc7+FAAHD26kpaWE7OwzgNAd6k1Nu0hJGc/Bg+vIzf1s27QpLS3leL15Hb6jQKCJhoaNpKVNw+1Oo7z8JUDJy7vA+bwOj2cYTU17qK39gJaWUrKy5tPcvB+3OwO/vxK/v5r09FkkJ48mOXmsU8Ys7/e5FDiyEv8lwLmdEv88Vb2hp21sxG+MMYevp8QfiwuCi4Hx7ZbHAft6WNcYY0yExSLxfwxMFZFJIpIEXAq8GIM4jDEmIQ36lA2q6heRbwGvEjrt/6iqrh/sOIwxJlHFZK4eVX0ZeDkWfRtjTKKzST+MMSbBWOI3xpgEY4nfGGMSjCV+Y4xJMENidk4RKQP6e+tuPlAewXCGAjvmxGDHnBgGcswTVLXL/OBDIvEPhIgs7+7OtXhmx5wY7JgTQzSO2Uo9xhiTYCzxG2NMgkmExP9Q36vEHTvmxGDHnBgifsxxX+M3xhjTUSKM+I0xxrRjid8YYxJM3CZ+EVkoIptFZJuI3BbreCJFRB4VkVIRWdeuLVdEXheRrc7PnHaffd/5DjaLyLmxiXpgRGS8iLwtIhtFZL2IfNtpj9vjFpEUEflIRNY4x/xTpz1ujxlCz+QWkVUi8pKzHNfHCyAiu0TkExFZLSLLnbboHreqxt2L0HTP24HJQBKwBpgR67gidGynAycA69q13QXc5ry/Dfhv5/0M59iTgUnOd+KO9TH045hHAyc47zOBLc6xxe1xAwJkOO+9wDLg5Hg+Zuc4bgaeBl5yluP6eJ1j2QXkd2qL6nHH64h/HrBNVXdo6CnHzwIXxTimiFDVpUBlp+aLgCec908An2/X/qyqNqvqTmAboe9mSFHV/aq60nlfB2wExhLHx60h9c6i13kpcXzMIjIOOB/4fbvmuD3ePkT1uOM18Y8FitotFztt8Wqkqu6HUJIERjjtcfc9iMhEYA6hEXBcH7dT9lgNlAKvq2q8H/N9wPeAYLu2eD7eVgq8JiIrRGSR0xbV447Jg1gGgXTTlojXrcbV9yAiGcDzwHdUtVaku8MLrdpN25A7blUNALNFJBt4QURm9rL6kD5mEbkAKFXVFSKyIJxNumkbMsfbyamquk9ERgCvi8imXtaNyHHH64g/0R7oXiIiowGcn6VOe9x8DyLiJZT0n1LVvzrNcX/cAKpaDSwBFhK/x3wqcKGI7CJUmj1LRJ4kfo+3jaruc36WAi8QKt1E9bjjNfEn2gPdXwSuct5fBfy9XfulIpIsIpOAqcBHMYhvQCQ0tH8E2Kiq97T7KG6PW0SGOyN9RCQV+AywiTg9ZlX9vqqOU9WJhP5/fUtVryBOj7eViKSLSGbre+AcYB3RPu5Yn9GO4pny8whd/bEd+GGs44ngcT0D7Ad8hH77XwvkAW8CW52fue3W/6HzHWwGPhvr+Pt5zKcR+nN2LbDaeZ0Xz8cNzAJWOce8Dvix0x63x9zuOBZw6KqeuD5eQlcernFe61tzVbSP26ZsMMaYBBOvpR5jjDE9sMRvjDEJxhK/McYkGEv8xhiTYCzxG2NMgrHEbxKaiAScWRFbXxGbyVVEJrafRdWYI0W8TtlgTLgaVXV2rIMwZjDZiN+YbjhzpP+3Myf+RyIyxWmfICJvisha52eB0z5SRF5w5s9fIyLznV25ReRhZ07915y7cBGRG0Vkg7OfZ2N0mCZBWeI3iS61U6nn39t9Vquq84BfE5o5Euf9H1R1FvAUcL/Tfj/wjqoeT+h5Ceud9qnAA6p6LFANXOy03wbMcfbzjegcmjHdszt3TUITkXpVzeimfRdwlqrucCaIO6CqeSJSDoxWVZ/Tvl9V80WkDBinqs3t9jGR0HTKU53lxYBXVX8hIq8A9cDfgL/pobn3jYk6G/Eb0zPt4X1P63Snud37AIfOq50PPADMBVaIiJ1vM4PGEr8xPfv3dj8/cN6/T2j2SIDLgXed928C10PbA1SG9bRTEXEB41X1bUIPHskGuvzVYUy02CjDJLpU5ylXrV5R1dZLOpNFZBmhAdJlTtuNwKMi8l2gDLjGaf828JCIXEtoZH89oVlUu+MGnhSRLEIP1rhXQ3PuGzMorMZvTDecGn+hqpbHOhZjIs1KPcYYk2BsxG+MMQnGRvzGGJNgLPEbY0yCscRvjDEJxhK/McYkGEv8xhiTYP4/w1RVYqcxMDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction_test = model.predict(X_test)    \n",
    "# print(y_test, prediction_test)\n",
    "# print(\"Mean sq. errror between y_test and predicted =\", np.mean(prediction_test-y_test)**2)\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training Loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Arousal Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Cross-entropy loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Arousal Training  Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "##model predictions\n",
    "###model already knows there are two outputs from the definition\n",
    "# predictions = model.predict(X_test)\n",
    "y_pred_aro= model_aro.predict(X_test)\n",
    "y_pred_aro = (y_pred_aro > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_aro = y_pred_aro.reshape([472,]) #Reshape needed for deriving table of actual vs predicted values\n",
    "y_pred_aro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_aro = (y_pred_aro > 0.5)#needed for deriving confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[236,   0],\n",
       "       [  0, 236]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Memory test for Valence\n",
    "cm2 = confusion_matrix(y_pred_aro, Y_aro)\n",
    "cm2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm2/np.sum(cm2), annot=True, \n",
    "            fmt='.2%', cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted\n",
       "0         1       True\n",
       "1         1       True\n",
       "2         1       True\n",
       "3         1       True\n",
       "4         1       True\n",
       "..      ...        ...\n",
       "467       0      False\n",
       "468       0      False\n",
       "469       0      False\n",
       "470       0      False\n",
       "471       0      False\n",
       "\n",
       "[472 rows x 2 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame({'Actual': Y_val, 'Predicted': y_pred_val})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names1 = ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7','F8', 'F9', 'F10', 'F11', 'F12', 'F13', 'F14', 'F15', 'F16', 'F17', 'F18', 'F19',\n",
    "          'F20','F21', 'F22', 'F23', 'F24', 'F25', 'F26', 'F27', 'F28','29', 'F30', 'F31', 'F32','F33', 'F34', 'F35',\n",
    "          'F36','F37', 'F38', 'F39', 'F40', 'F41', 'F42', 'F43', 'F44','45', 'F46', 'F47', 'F48','F49', 'F50', 'F51', 'F52', \n",
    "          'F53', 'F54', 'F55','F56', 'F57', 'F58', 'F59', 'F60','F61', 'F62', 'F63', 'F64', 'F65', 'F66', 'F67','F68', \n",
    "          'F69', 'F70','F71', 'F72','Valence','Arousal']\n",
    "\n",
    "# happy_df = pd.read_csv(dirname + datasethappy, header=0, names=names1)\n",
    "df = pd.read_csv('C:/Users/DELL/S01/finals/Final_mfcc_EC_S01.csv',  header =None, index_col=None,names=names1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
